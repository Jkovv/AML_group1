{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "453ab9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.11.10)\n",
      "Requirement already satisfied: anyio in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from accelerate) (2.9.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.18.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from torch>=2.0.0->accelerate) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc302f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a872b2e6-501a-4469-b4db-84a80dc2ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"processed_bird_data\"\n",
    "TEST_DATA_PATH = \"processed_bird_test_data\"\n",
    "MODEL_NAME = \"google/mobilenet_v2_1.0_224\"\n",
    "BATCH_SIZE = 32 \n",
    "EPOCHS = 10\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfcee223-b046-4569-989b-0b45f57abc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "try:\n",
    "    dataset = load_from_disk(DATA_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {DATA_PATH} not found.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e845a9c-6c39-4c9d-98f0-1cd977400a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2890d50-d6de-4745-a3a3-a76e7481584b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 105\n",
      "Val batches:   19\n"
     ]
    }
   ],
   "source": [
    "def transform(batch):\n",
    "    inputs = feature_extractor([x for x in batch[\"image\"]], return_tensors=\"pt\")\n",
    "    inputs[\"label\"] = batch[\"label\"]\n",
    "    return inputs\n",
    "\n",
    "dataset = dataset.with_transform(transform)\n",
    "\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "train_loader = DataLoader(dataset[\"train\"], batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(dataset[\"validation\"], batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches:   {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c91cadb-93f6-4662-8675-5d058905e7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Baseline Model (MobileNetV2)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileNetV2ForImageClassification were not initialized from the model checkpoint at google/mobilenet_v2_1.0_224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1001]) in the checkpoint and torch.Size([200]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1001, 1280]) in the checkpoint and torch.Size([200, 1280]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready.\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing Baseline Model (MobileNetV2)...\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=200,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Model ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35991d96-f2d4-4820-8914-2c398371aad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training loop...\n",
      "\n",
      "[Epoch 1] Batch 0/105 | loss=5.2987\n",
      "[Epoch 1] Batch 20/105 | loss=5.0515\n",
      "[Epoch 1] Batch 40/105 | loss=4.9252\n",
      "[Epoch 1] Batch 60/105 | loss=4.1871\n",
      "[Epoch 1] Batch 80/105 | loss=3.5144\n",
      "[Epoch 1] Batch 100/105 | loss=3.7427\n",
      "Train: loss=4.4456, acc=0.1417\n",
      "Val:   loss=3.6121, acc=0.2683\n",
      "Best model saved!\n",
      "------------------------------\n",
      "[Epoch 2] Batch 0/105 | loss=3.0475\n",
      "[Epoch 2] Batch 20/105 | loss=2.8099\n",
      "[Epoch 2] Batch 40/105 | loss=2.1361\n",
      "[Epoch 2] Batch 60/105 | loss=2.4891\n",
      "[Epoch 2] Batch 80/105 | loss=2.3831\n",
      "[Epoch 2] Batch 100/105 | loss=1.7832\n",
      "Train: loss=2.2788, acc=0.5391\n",
      "Val:   loss=2.4471, acc=0.4177\n",
      "Best model saved!\n",
      "------------------------------\n",
      "[Epoch 3] Batch 0/105 | loss=1.0102\n",
      "[Epoch 3] Batch 20/105 | loss=1.5037\n",
      "[Epoch 3] Batch 40/105 | loss=1.3224\n",
      "[Epoch 3] Batch 60/105 | loss=1.2309\n",
      "[Epoch 3] Batch 80/105 | loss=1.0523\n",
      "[Epoch 3] Batch 100/105 | loss=1.1437\n",
      "Train: loss=1.2398, acc=0.7675\n",
      "Val:   loss=2.1713, acc=0.4533\n",
      "Best model saved!\n",
      "------------------------------\n",
      "[Epoch 4] Batch 0/105 | loss=0.6380\n",
      "[Epoch 4] Batch 20/105 | loss=0.7057\n",
      "[Epoch 4] Batch 40/105 | loss=0.7190\n",
      "[Epoch 4] Batch 60/105 | loss=0.6663\n",
      "[Epoch 4] Batch 80/105 | loss=0.7564\n",
      "[Epoch 4] Batch 100/105 | loss=0.7269\n",
      "Train: loss=0.6518, acc=0.9155\n",
      "Val:   loss=1.9307, acc=0.5110\n",
      "Best model saved!\n",
      "------------------------------\n",
      "[Epoch 5] Batch 0/105 | loss=0.3881\n",
      "[Epoch 5] Batch 20/105 | loss=0.4919\n",
      "[Epoch 5] Batch 40/105 | loss=0.3207\n",
      "[Epoch 5] Batch 60/105 | loss=0.2500\n",
      "[Epoch 5] Batch 80/105 | loss=0.2554\n",
      "[Epoch 5] Batch 100/105 | loss=0.2749\n",
      "Train: loss=0.3235, acc=0.9757\n",
      "Val:   loss=1.8468, acc=0.5467\n",
      "Best model saved!\n",
      "------------------------------\n",
      "[Epoch 6] Batch 0/105 | loss=0.1671\n",
      "[Epoch 6] Batch 20/105 | loss=0.1289\n",
      "[Epoch 6] Batch 40/105 | loss=0.1413\n",
      "[Epoch 6] Batch 60/105 | loss=0.1117\n",
      "[Epoch 6] Batch 80/105 | loss=0.1238\n",
      "[Epoch 6] Batch 100/105 | loss=0.1673\n",
      "Train: loss=0.1633, acc=0.9949\n",
      "Val:   loss=1.8977, acc=0.5059\n",
      "------------------------------\n",
      "[Epoch 7] Batch 0/105 | loss=0.0898\n",
      "[Epoch 7] Batch 20/105 | loss=0.0740\n",
      "[Epoch 7] Batch 40/105 | loss=0.0970\n",
      "[Epoch 7] Batch 60/105 | loss=0.1077\n",
      "[Epoch 7] Batch 80/105 | loss=0.0747\n",
      "[Epoch 7] Batch 100/105 | loss=0.0765\n",
      "Train: loss=0.0980, acc=0.9991\n",
      "Val:   loss=1.9458, acc=0.4941\n",
      "------------------------------\n",
      "[Epoch 8] Batch 0/105 | loss=0.0570\n",
      "[Epoch 8] Batch 20/105 | loss=0.0985\n",
      "[Epoch 8] Batch 40/105 | loss=0.0624\n",
      "[Epoch 8] Batch 60/105 | loss=0.0578\n",
      "[Epoch 8] Batch 80/105 | loss=0.0556\n",
      "[Epoch 8] Batch 100/105 | loss=0.0527\n",
      "Train: loss=0.0693, acc=0.9997\n",
      "Val:   loss=2.0387, acc=0.4924\n",
      "------------------------------\n",
      "[Epoch 9] Batch 0/105 | loss=0.0485\n",
      "[Epoch 9] Batch 20/105 | loss=0.0725\n",
      "[Epoch 9] Batch 40/105 | loss=0.0323\n",
      "[Epoch 9] Batch 60/105 | loss=0.0403\n",
      "[Epoch 9] Batch 80/105 | loss=0.0552\n",
      "[Epoch 9] Batch 100/105 | loss=0.0619\n",
      "Train: loss=0.0493, acc=0.9991\n",
      "Val:   loss=1.9418, acc=0.5348\n",
      "------------------------------\n",
      "[Epoch 10] Batch 0/105 | loss=0.0249\n",
      "[Epoch 10] Batch 20/105 | loss=0.0264\n",
      "[Epoch 10] Batch 40/105 | loss=0.0367\n",
      "[Epoch 10] Batch 60/105 | loss=0.0278\n",
      "[Epoch 10] Batch 80/105 | loss=0.0216\n",
      "[Epoch 10] Batch 100/105 | loss=0.0309\n",
      "Train: loss=0.0302, acc=1.0000\n",
      "Val:   loss=1.8093, acc=0.5416\n",
      "------------------------------\n",
      "\n",
      "Training complete. Best Validation Accuracy: 0.5467\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "save_path = \"baseline_best_model.pth\"\n",
    "\n",
    "print(\"Starting training loop...\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for i, batch in enumerate(train_loader):\n",
    "        pixel_values = batch[\"pixel_values\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass \n",
    "        outputs = model(pixel_values=pixel_values)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # stats\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            print(f\"[Epoch {epoch+1}] Batch {i}/{len(train_loader)} | loss={loss.item():.4f}\")\n",
    "\n",
    "    train_epoch_loss = running_loss / len(train_loader)\n",
    "    train_epoch_acc = correct_train / total_train\n",
    "    \n",
    "    # val\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            pixel_values = batch[\"pixel_values\"].to(DEVICE)\n",
    "            labels = batch[\"labels\"].to(DEVICE)\n",
    "            \n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            \n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            \n",
    "    val_epoch_loss = val_running_loss / len(val_loader)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    \n",
    "    # final raport (per epoch)\n",
    "    print(f\"Train: loss={train_epoch_loss:.4f}, acc={train_epoch_acc:.4f}\")\n",
    "    print(f\"Val:   loss={val_epoch_loss:.4f}, acc={val_epoch_acc:.4f}\")\n",
    "    \n",
    "    # saving the best model\n",
    "    if val_epoch_acc > best_val_acc:\n",
    "        best_val_acc = val_epoch_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(\"Best model saved!\")\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(f\"\\nTraining complete. Best Validation Accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4497876f-e27d-440e-9fe7-a666230b0f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Now, running on the test set\n",
      "Loading test data from processed_bird_test_data...\n",
      "Loading best weights from baseline_best_model.pth...\n",
      "Testing...\n",
      "[Test] Batch 0/125\n",
      "[Test] Batch 20/125\n",
      "[Test] Batch 40/125\n",
      "[Test] Batch 60/125\n",
      "[Test] Batch 80/125\n",
      "[Test] Batch 100/125\n",
      "[Test] Batch 120/125\n",
      "\n",
      "==============================\n",
      "FINAL TEST RESULTS:\n",
      "Test Loss:     8.0590\n",
      "Test Accuracy: 0.0030 (0.30%)\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Now, running on the test set\")\n",
    "\n",
    "if os.path.exists(TEST_DATA_PATH):\n",
    "    print(f\"Loading test data from {TEST_DATA_PATH}...\")\n",
    "    try:\n",
    "        test_dataset_raw = load_from_disk(TEST_DATA_PATH)\n",
    "        if isinstance(test_dataset_raw, dict) and \"test\" in test_dataset_raw:\n",
    "            test_ds = test_dataset_raw[\"test\"]\n",
    "        else:\n",
    "            test_ds = test_dataset_raw\n",
    "            \n",
    "        test_ds = test_ds.with_transform(transform)\n",
    "        test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading test data: {e}\")\n",
    "        test_loader = None\n",
    "else:\n",
    "    print(\"Test data folder not found.\")\n",
    "    test_loader = None\n",
    "\n",
    "if test_loader:\n",
    "    print(f\"Loading best weights from {save_path}...\")\n",
    "    model.load_state_dict(torch.load(save_path, map_location=DEVICE))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    \n",
    "    print(\"Testing...\")\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            pixel_values = batch[\"pixel_values\"].to(DEVICE)\n",
    "            labels = batch[\"labels\"].to(DEVICE)\n",
    "            \n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            \n",
    "            if i % 20 == 0:\n",
    "                 print(f\"[Test] Batch {i}/{len(test_loader)}\")\n",
    "\n",
    "    final_loss = test_loss / len(test_loader)\n",
    "    final_acc = correct_test / total_test\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"FINAL TEST RESULTS:\")\n",
    "    print(f\"Test Loss:     {final_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {final_acc:.4f} ({final_acc*100:.2f}%)\")\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cee3a18-fa4a-496b-a0b4-991c663ac28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ? blind "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7f8208-e71e-48f7-b612-fff1efece521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the below code after the 1st part finished running (not optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea3ab757-1247-4ceb-acd3-98baa5038f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best weights from baseline_best_model.pth...\n",
      "Predicting classes for test images...\n",
      "[Submission] Processing batch 0/125\n",
      "[Submission] Processing batch 20/125\n",
      "[Submission] Processing batch 40/125\n",
      "[Submission] Processing batch 60/125\n",
      "[Submission] Processing batch 80/125\n",
      "[Submission] Processing batch 100/125\n",
      "[Submission] Processing batch 120/125\n",
      "Retrieving IDs from disk...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from datasets import load_from_disk\n",
    "\n",
    "save_path = \"baseline_best_model.pth\"\n",
    "TEST_DATA_PATH = \"processed_bird_test_data\"\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "if os.path.exists(save_path):\n",
    "    print(f\"Loading best weights from {save_path}...\")\n",
    "    model.load_state_dict(torch.load(save_path, map_location=DEVICE))\n",
    "else:\n",
    "    print(f\"WARNING: File '{save_path}' not found! Using current model weights.\")\n",
    "\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "print(f\"Predicting classes for test images...\")\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        pixel_values = batch[\"pixel_values\"].to(DEVICE)\n",
    "        \n",
    "        outputs = model(pixel_values=pixel_values)\n",
    "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            print(f\"[Submission] Processing batch {i}/{len(test_loader)}\")\n",
    "\n",
    "print(\"Retrieving IDs from disk...\")\n",
    "\n",
    "clean_test_dataset = load_from_disk(TEST_DATA_PATH)\n",
    "\n",
    "if isinstance(clean_test_dataset, dict) and \"test\" in clean_test_dataset:\n",
    "    clean_ds = clean_test_dataset[\"test\"]\n",
    "else:\n",
    "    clean_ds = clean_test_dataset\n",
    "\n",
    "if \"id\" in clean_ds.column_names:\n",
    "    submission_ids = clean_ds[\"id\"]\n",
    "else:\n",
    "    print(\"Warning: 'id' column missing in raw data. Generating index.\")\n",
    "    submission_ids = range(len(all_preds))\n",
    "\n",
    "if len(submission_ids) != len(all_preds):\n",
    "    print(f\"ERROR: ID count ({len(submission_ids)}) != Prediction count ({len(all_preds)})\")\n",
    "else:\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"id\": submission_ids,\n",
    "        \"label\": all_preds\n",
    "    })\n",
    "\n",
    "    csv_filename = \"baseline_submission.csv\"\n",
    "    submission_df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8650d-e922-4a57-8a34-1905d4585748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
