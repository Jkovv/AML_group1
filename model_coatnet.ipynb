{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e521e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install timm\n",
    "#!pip install ipywidgets\n",
    "#!pip install optuna plotly\n",
    "#!pip install kaleido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c506a5cf",
   "metadata": {},
   "source": [
    "# new model - coatnet\n",
    "hybrid architecture - Convolution + Attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284eb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Loading and transforming data.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import optuna\n",
    "import evaluate\n",
    "import sys\n",
    "import shutil\n",
    "import safetensors.torch\n",
    "import numpy as np\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "from optuna.visualization.matplotlib import plot_optimization_history, plot_param_importances\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "from datasets import load_from_disk\n",
    "from transformers import TrainingArguments, Trainer, set_seed\n",
    "from torchvision.transforms import (\n",
    "    Compose, Resize, CenterCrop, ToTensor, Normalize, \n",
    "    RandomHorizontalFlip, RandomResizedCrop\n",
    ")\n",
    "\n",
    "DATA_PATH = \"processed_bird_data\"\n",
    "OUTPUT_DIR = \"new_model_checkpoints\"\n",
    "MODEL_NAME = \"coatnet_0_rw_224\"\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"Loading and transforming data.\")\n",
    "dataset = load_from_disk(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4adfe7b",
   "metadata": {},
   "source": [
    "Applying Aggressive Data Augmentation to prevent overfitting:\n",
    "\n",
    "1. Does random resize/zoom (scale 0.8â€“1.0). Forces the model to recognize a bird by looking at its specific feature (e.g. the head, wing, etc.) instead of the background (e.g. tress).\n",
    "2. Incorporates horizontal flipping to double the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07295e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ready.\n"
     ]
    }
   ],
   "source": [
    "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "_train_transforms = Compose([\n",
    "    RandomResizedCrop(224, scale=(0.8, 1.0)), \n",
    "    RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "_val_transforms = Compose([\n",
    "    Resize(256),\n",
    "    CenterCrop(224),\n",
    "    ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "def train_transforms(batch):\n",
    "    batch[\"pixel_values\"] = [_train_transforms(image.convert(\"RGB\")) for image in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "def val_transforms(batch):\n",
    "    batch[\"pixel_values\"] = [_val_transforms(image.convert(\"RGB\")) for image in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "# fix nonetype error\n",
    "dataset[\"train\"] = dataset[\"train\"].map(\n",
    "    train_transforms, batched=True, remove_columns=[\"image\"]\n",
    ")\n",
    "dataset[\"validation\"] = dataset[\"validation\"].map(\n",
    "    val_transforms, batched=True, remove_columns=[\"image\"]\n",
    ")\n",
    "\n",
    "print(\"Data ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66360a0",
   "metadata": {},
   "source": [
    "# Training\n",
    "Initializing CoAtNet model with random weights, no pretraining. \n",
    "\n",
    "It uses standard Convolutional layers in the early stages to extract low-level features (edges, textures), and then uses Transformer layers in the final stages to understand the global shape of the bird. Using Bayesian optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7c68fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 00:14:53,795] A new study created in memory with name: no-name-d78dbc17-a704-40ad-b711-2479d1a99134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting optimization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2425, 'grad_norm': 11.513040542602539, 'learning_rate': 2.8994837191926922e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 5.110533714294434, 'eval_accuracy': 0.015280135823429542, 'eval_runtime': 51.7044, 'eval_samples_per_second': 11.392, 'eval_steps_per_second': 1.431, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8755, 'grad_norm': 12.688076972961426, 'learning_rate': 2.17633457307575e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 4.95403528213501, 'eval_accuracy': 0.03904923599320883, 'eval_runtime': 50.409, 'eval_samples_per_second': 11.684, 'eval_steps_per_second': 1.468, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.6496, 'grad_norm': 14.168149948120117, 'learning_rate': 1.4531854269588076e-05, 'epoch': 3.0}\n",
      "{'eval_loss': 4.848221302032471, 'eval_accuracy': 0.04584040747028863, 'eval_runtime': 50.8844, 'eval_samples_per_second': 11.575, 'eval_steps_per_second': 1.454, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4763, 'grad_norm': 15.0447416305542, 'learning_rate': 7.3003628084186556e-06, 'epoch': 4.0}\n",
      "{'eval_loss': 4.792064189910889, 'eval_accuracy': 0.05432937181663837, 'eval_runtime': 50.7008, 'eval_samples_per_second': 11.617, 'eval_steps_per_second': 1.46, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.369, 'grad_norm': 15.150389671325684, 'learning_rate': 6.88713472492326e-08, 'epoch': 5.0}\n",
      "{'eval_loss': 4.775396347045898, 'eval_accuracy': 0.05602716468590832, 'eval_runtime': 49.7514, 'eval_samples_per_second': 11.839, 'eval_steps_per_second': 1.487, 'epoch': 5.0}\n",
      "{'train_runtime': 2243.7132, 'train_samples_per_second': 7.436, 'train_steps_per_second': 0.234, 'train_loss': 4.72258062453497, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "[I 2025-12-13 00:53:08,847] Trial 0 finished with value: 0.05602716468590832 and parameters: {'lr': 3.2507275901637785e-05, 'weight_decay': 0.00819586286364869}. Best is trial 0 with value: 0.05602716468590832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.775396347045898, 'eval_accuracy': 0.05602716468590832, 'eval_runtime': 50.8297, 'eval_samples_per_second': 11.588, 'eval_steps_per_second': 1.456, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2839, 'grad_norm': 7.288018703460693, 'learning_rate': 0.000524728714543677, 'epoch': 1.0}\n",
      "{'eval_loss': 5.175487995147705, 'eval_accuracy': 0.011884550084889643, 'eval_runtime': 52.4591, 'eval_samples_per_second': 11.228, 'eval_steps_per_second': 1.411, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8622, 'grad_norm': 6.568967342376709, 'learning_rate': 0.000393858132531596, 'epoch': 2.0}\n",
      "{'eval_loss': 4.743896961212158, 'eval_accuracy': 0.03735144312393888, 'eval_runtime': 50.492, 'eval_samples_per_second': 11.665, 'eval_steps_per_second': 1.466, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4379, 'grad_norm': 8.712620735168457, 'learning_rate': 0.000262987550519515, 'epoch': 3.0}\n",
      "{'eval_loss': 4.489076614379883, 'eval_accuracy': 0.0730050933786078, 'eval_runtime': 50.0676, 'eval_samples_per_second': 11.764, 'eval_steps_per_second': 1.478, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0204, 'grad_norm': 10.081070899963379, 'learning_rate': 0.0001321169685074341, 'epoch': 4.0}\n",
      "{'eval_loss': 4.24075174331665, 'eval_accuracy': 0.0730050933786078, 'eval_runtime': 50.788, 'eval_samples_per_second': 11.597, 'eval_steps_per_second': 1.457, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6804, 'grad_norm': 12.151529312133789, 'learning_rate': 1.2463864953531518e-06, 'epoch': 5.0}\n",
      "{'eval_loss': 4.113521575927734, 'eval_accuracy': 0.0967741935483871, 'eval_runtime': 51.1191, 'eval_samples_per_second': 11.522, 'eval_steps_per_second': 1.448, 'epoch': 5.0}\n",
      "{'train_runtime': 2222.0846, 'train_samples_per_second': 7.509, 'train_steps_per_second': 0.236, 'train_loss': 4.4569436500186015, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "[I 2025-12-13 01:31:00,961] Trial 1 finished with value: 0.0967741935483871 and parameters: {'lr': 0.0005882944258066877, 'weight_decay': 0.06440531064566528}. Best is trial 1 with value: 0.0967741935483871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.113521575927734, 'eval_accuracy': 0.0967741935483871, 'eval_runtime': 49.2007, 'eval_samples_per_second': 11.971, 'eval_steps_per_second': 1.504, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2323, 'grad_norm': 11.302532196044922, 'learning_rate': 3.3822391978716245e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 5.105463981628418, 'eval_accuracy': 0.01697792869269949, 'eval_runtime': 51.2153, 'eval_samples_per_second': 11.5, 'eval_steps_per_second': 1.445, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8834, 'grad_norm': 12.119502067565918, 'learning_rate': 2.538687853984402e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 4.975046157836914, 'eval_accuracy': 0.035653650254668934, 'eval_runtime': 49.6144, 'eval_samples_per_second': 11.872, 'eval_steps_per_second': 1.492, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.6507, 'grad_norm': 13.61575984954834, 'learning_rate': 1.69513651009718e-05, 'epoch': 3.0}\n",
      "{'eval_loss': 4.849087715148926, 'eval_accuracy': 0.04753820033955857, 'eval_runtime': 50.4508, 'eval_samples_per_second': 11.675, 'eval_steps_per_second': 1.467, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4693, 'grad_norm': 13.890074729919434, 'learning_rate': 8.515851662099578e-06, 'epoch': 4.0}\n",
      "{'eval_loss': 4.793532371520996, 'eval_accuracy': 0.04753820033955857, 'eval_runtime': 41.106, 'eval_samples_per_second': 14.329, 'eval_steps_per_second': 1.8, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3453, 'grad_norm': 14.889199256896973, 'learning_rate': 8.03382232273545e-08, 'epoch': 5.0}\n",
      "{'eval_loss': 4.760318279266357, 'eval_accuracy': 0.05602716468590832, 'eval_runtime': 41.2497, 'eval_samples_per_second': 14.279, 'eval_steps_per_second': 1.794, 'epoch': 5.0}\n",
      "{'train_runtime': 2103.5144, 'train_samples_per_second': 7.932, 'train_steps_per_second': 0.25, 'train_loss': 4.716188151041667, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "[I 2025-12-13 02:06:44,700] Trial 2 finished with value: 0.05602716468590832 and parameters: {'lr': 3.7919641363311324e-05, 'weight_decay': 0.006816467600356044}. Best is trial 1 with value: 0.0967741935483871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.760318279266357, 'eval_accuracy': 0.05602716468590832, 'eval_runtime': 39.2737, 'eval_samples_per_second': 14.997, 'eval_steps_per_second': 1.884, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2492, 'grad_norm': 11.673582077026367, 'learning_rate': 2.5004078948896126e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 5.128129482269287, 'eval_accuracy': 0.013582342954159592, 'eval_runtime': 40.7427, 'eval_samples_per_second': 14.457, 'eval_steps_per_second': 1.816, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9196, 'grad_norm': 12.197758674621582, 'learning_rate': 1.8767907239551488e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 5.014156818389893, 'eval_accuracy': 0.03225806451612903, 'eval_runtime': 40.5498, 'eval_samples_per_second': 14.525, 'eval_steps_per_second': 1.825, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.7159, 'grad_norm': 13.201201438903809, 'learning_rate': 1.2531735530206846e-05, 'epoch': 3.0}\n",
      "{'eval_loss': 4.912810802459717, 'eval_accuracy': 0.04584040747028863, 'eval_runtime': 43.0977, 'eval_samples_per_second': 13.667, 'eval_steps_per_second': 1.717, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5697, 'grad_norm': 13.703865051269531, 'learning_rate': 6.2955638208622075e-06, 'epoch': 4.0}\n",
      "{'eval_loss': 4.868636608123779, 'eval_accuracy': 0.044142614601018676, 'eval_runtime': 40.9062, 'eval_samples_per_second': 14.399, 'eval_steps_per_second': 1.809, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.47, 'grad_norm': 14.587310791015625, 'learning_rate': 5.9392111517567994e-08, 'epoch': 5.0}\n",
      "{'eval_loss': 4.841075420379639, 'eval_accuracy': 0.05263157894736842, 'eval_runtime': 51.5279, 'eval_samples_per_second': 11.431, 'eval_steps_per_second': 1.436, 'epoch': 5.0}\n",
      "{'train_runtime': 1924.3768, 'train_samples_per_second': 8.67, 'train_steps_per_second': 0.273, 'train_loss': 4.784867175874256, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "[I 2025-12-13 02:39:41,093] Trial 3 finished with value: 0.05263157894736842 and parameters: {'lr': 2.8033076636292094e-05, 'weight_decay': 0.02063456025962388}. Best is trial 1 with value: 0.0967741935483871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.841075420379639, 'eval_accuracy': 0.05263157894736842, 'eval_runtime': 51.2721, 'eval_samples_per_second': 11.488, 'eval_steps_per_second': 1.443, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2382, 'grad_norm': 9.173094749450684, 'learning_rate': 0.00026313567250486116, 'epoch': 1.0}\n",
      "{'eval_loss': 5.097543716430664, 'eval_accuracy': 0.01867572156196944, 'eval_runtime': 51.0921, 'eval_samples_per_second': 11.528, 'eval_steps_per_second': 1.448, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8038, 'grad_norm': 9.52728271484375, 'learning_rate': 0.00019750801071623784, 'epoch': 2.0}\n",
      "{'eval_loss': 4.719091415405273, 'eval_accuracy': 0.04074702886247878, 'eval_runtime': 51.048, 'eval_samples_per_second': 11.538, 'eval_steps_per_second': 1.45, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3542, 'grad_norm': 12.75381088256836, 'learning_rate': 0.0001318803489276145, 'epoch': 3.0}\n",
      "{'eval_loss': 4.43895149230957, 'eval_accuracy': 0.06791171477079797, 'eval_runtime': 51.2737, 'eval_samples_per_second': 11.487, 'eval_steps_per_second': 1.443, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.91, 'grad_norm': 12.871563911437988, 'learning_rate': 6.625268713899118e-05, 'epoch': 4.0}\n",
      "{'eval_loss': 4.1870598793029785, 'eval_accuracy': 0.09507640067911714, 'eval_runtime': 51.2085, 'eval_samples_per_second': 11.502, 'eval_steps_per_second': 1.445, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5558, 'grad_norm': 14.473942756652832, 'learning_rate': 6.250253503678412e-07, 'epoch': 5.0}\n",
      "{'eval_loss': 4.082765102386475, 'eval_accuracy': 0.0899830220713073, 'eval_runtime': 40.3255, 'eval_samples_per_second': 14.606, 'eval_steps_per_second': 1.835, 'epoch': 5.0}\n",
      "{'train_runtime': 2252.9722, 'train_samples_per_second': 7.406, 'train_steps_per_second': 0.233, 'train_loss': 4.372388334728423, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "[I 2025-12-13 03:17:54,511] Trial 4 finished with value: 0.0899830220713073 and parameters: {'lr': 0.0002950119653736211, 'weight_decay': 0.001162862789165195}. Best is trial 1 with value: 0.0967741935483871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.082765102386475, 'eval_accuracy': 0.0899830220713073, 'eval_runtime': 39.527, 'eval_samples_per_second': 14.901, 'eval_steps_per_second': 1.872, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2904, 'grad_norm': 7.1837053298950195, 'learning_rate': 0.0005518213755445285, 'epoch': 1.0}\n",
      "{'eval_loss': 5.184633255004883, 'eval_accuracy': 0.013582342954159592, 'eval_runtime': 41.8316, 'eval_samples_per_second': 14.08, 'eval_steps_per_second': 1.769, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8779, 'grad_norm': 6.250971794128418, 'learning_rate': 0.00041419371656073873, 'epoch': 2.0}\n",
      "{'eval_loss': 4.761796474456787, 'eval_accuracy': 0.04074702886247878, 'eval_runtime': 40.1602, 'eval_samples_per_second': 14.666, 'eval_steps_per_second': 1.843, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4508, 'grad_norm': 10.962923049926758, 'learning_rate': 0.00027656605757694897, 'epoch': 3.0}\n",
      "{'eval_loss': 4.488531589508057, 'eval_accuracy': 0.06451612903225806, 'eval_runtime': 42.178, 'eval_samples_per_second': 13.965, 'eval_steps_per_second': 1.754, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0235, 'grad_norm': 8.872998237609863, 'learning_rate': 0.0001389383985931592, 'epoch': 4.0}\n",
      "{'eval_loss': 4.225668430328369, 'eval_accuracy': 0.09168081494057725, 'eval_runtime': 41.4315, 'eval_samples_per_second': 14.216, 'eval_steps_per_second': 1.786, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6756, 'grad_norm': 11.283105850219727, 'learning_rate': 1.3107396093694264e-06, 'epoch': 5.0}\n",
      "{'eval_loss': 4.092563629150391, 'eval_accuracy': 0.0899830220713073, 'eval_runtime': 40.5756, 'eval_samples_per_second': 14.516, 'eval_steps_per_second': 1.824, 'epoch': 5.0}\n",
      "{'train_runtime': 1822.6555, 'train_samples_per_second': 9.154, 'train_steps_per_second': 0.288, 'train_loss': 4.463638044084822, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "[I 2025-12-13 03:48:58,105] Trial 5 finished with value: 0.0899830220713073 and parameters: {'lr': 0.0006186690956223693, 'weight_decay': 0.00727142749383276}. Best is trial 1 with value: 0.0967741935483871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.092563629150391, 'eval_accuracy': 0.0899830220713073, 'eval_runtime': 40.0819, 'eval_samples_per_second': 14.695, 'eval_steps_per_second': 1.846, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2586, 'grad_norm': 11.834840774536133, 'learning_rate': 2.1429903784024285e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 5.141763210296631, 'eval_accuracy': 0.011884550084889643, 'eval_runtime': 41.9354, 'eval_samples_per_second': 14.045, 'eval_steps_per_second': 1.765, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9402, 'grad_norm': 12.288898468017578, 'learning_rate': 1.608515343408949e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 5.032883167266846, 'eval_accuracy': 0.030560271646859084, 'eval_runtime': 40.7674, 'eval_samples_per_second': 14.448, 'eval_steps_per_second': 1.815, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.7494, 'grad_norm': 13.115076065063477, 'learning_rate': 1.074040308415469e-05, 'epoch': 3.0}\n",
      "{'eval_loss': 4.943479537963867, 'eval_accuracy': 0.042444821731748725, 'eval_runtime': 40.6859, 'eval_samples_per_second': 14.477, 'eval_steps_per_second': 1.819, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.6193, 'grad_norm': 13.647010803222656, 'learning_rate': 5.395652734219892e-06, 'epoch': 4.0}\n",
      "{'eval_loss': 4.905057430267334, 'eval_accuracy': 0.04584040747028863, 'eval_runtime': 40.3831, 'eval_samples_per_second': 14.585, 'eval_steps_per_second': 1.832, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5314, 'grad_norm': 14.3569974899292, 'learning_rate': 5.0902384285093315e-08, 'epoch': 5.0}\n",
      "{'eval_loss': 4.879743576049805, 'eval_accuracy': 0.05263157894736842, 'eval_runtime': 40.8107, 'eval_samples_per_second': 14.432, 'eval_steps_per_second': 1.813, 'epoch': 5.0}\n",
      "{'train_runtime': 1847.3997, 'train_samples_per_second': 9.032, 'train_steps_per_second': 0.284, 'train_loss': 4.8197663806733635, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "[I 2025-12-13 04:20:26,002] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.879743576049805, 'eval_accuracy': 0.05263157894736842, 'eval_runtime': 39.6901, 'eval_samples_per_second': 14.84, 'eval_steps_per_second': 1.864, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2425, 'grad_norm': 8.95525074005127, 'learning_rate': 0.00028302710348085636, 'epoch': 1.0}\n",
      "{'eval_loss': 5.110074043273926, 'eval_accuracy': 0.01697792869269949, 'eval_runtime': 44.5459, 'eval_samples_per_second': 13.222, 'eval_steps_per_second': 1.661, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8091, 'grad_norm': 9.229939460754395, 'learning_rate': 0.00021243839596187794, 'epoch': 2.0}\n",
      "{'eval_loss': 4.722928047180176, 'eval_accuracy': 0.042444821731748725, 'eval_runtime': 42.5688, 'eval_samples_per_second': 13.836, 'eval_steps_per_second': 1.738, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3552, 'grad_norm': 12.453908920288086, 'learning_rate': 0.00014184968844289952, 'epoch': 3.0}\n",
      "{'eval_loss': 4.42811918258667, 'eval_accuracy': 0.06960950764006792, 'eval_runtime': 40.7863, 'eval_samples_per_second': 14.441, 'eval_steps_per_second': 1.814, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9021, 'grad_norm': 12.528932571411133, 'learning_rate': 7.126098092392109e-05, 'epoch': 4.0}\n",
      "{'eval_loss': 4.174158096313477, 'eval_accuracy': 0.09507640067911714, 'eval_runtime': 41.1365, 'eval_samples_per_second': 14.318, 'eval_steps_per_second': 1.799, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5471, 'grad_norm': 12.523170471191406, 'learning_rate': 6.722734049426517e-07, 'epoch': 5.0}\n",
      "{'eval_loss': 4.066380023956299, 'eval_accuracy': 0.0831918505942275, 'eval_runtime': 40.5513, 'eval_samples_per_second': 14.525, 'eval_steps_per_second': 1.825, 'epoch': 5.0}\n",
      "{'train_runtime': 1907.1202, 'train_samples_per_second': 8.749, 'train_steps_per_second': 0.275, 'train_loss': 4.371198788597471, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "[I 2025-12-13 04:52:54,008] Trial 7 finished with value: 0.0831918505942275 and parameters: {'lr': 0.0003173130471329316, 'weight_decay': 0.0015595372757872916}. Best is trial 1 with value: 0.0967741935483871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.066380023956299, 'eval_accuracy': 0.0831918505942275, 'eval_runtime': 39.9678, 'eval_samples_per_second': 14.737, 'eval_steps_per_second': 1.851, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2944, 'grad_norm': 6.613032341003418, 'learning_rate': 0.000608234885038849, 'epoch': 1.0}\n",
      "{'eval_loss': 5.211208820343018, 'eval_accuracy': 0.01697792869269949, 'eval_runtime': 41.6639, 'eval_samples_per_second': 14.137, 'eval_steps_per_second': 1.776, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.887, 'grad_norm': 6.35720157623291, 'learning_rate': 0.00045653734839020495, 'epoch': 2.0}\n",
      "{'eval_loss': 4.775773048400879, 'eval_accuracy': 0.03735144312393888, 'eval_runtime': 40.3377, 'eval_samples_per_second': 14.602, 'eval_steps_per_second': 1.835, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4794, 'grad_norm': 9.68553352355957, 'learning_rate': 0.0003048398117415609, 'epoch': 3.0}\n",
      "{'eval_loss': 4.531720161437988, 'eval_accuracy': 0.06112054329371817, 'eval_runtime': 40.4763, 'eval_samples_per_second': 14.552, 'eval_steps_per_second': 1.828, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.0728, 'grad_norm': 9.154584884643555, 'learning_rate': 0.00015314227509291686, 'epoch': 4.0}\n",
      "{'eval_loss': 4.272819995880127, 'eval_accuracy': 0.0865874363327674, 'eval_runtime': 40.6914, 'eval_samples_per_second': 14.475, 'eval_steps_per_second': 1.819, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7293, 'grad_norm': 11.702695846557617, 'learning_rate': 1.4447384442728005e-06, 'epoch': 5.0}\n",
      "{'eval_loss': 4.135818958282471, 'eval_accuracy': 0.08828522920203735, 'eval_runtime': 40.4471, 'eval_samples_per_second': 14.562, 'eval_steps_per_second': 1.83, 'epoch': 5.0}\n",
      "{'train_runtime': 1786.8774, 'train_samples_per_second': 9.338, 'train_steps_per_second': 0.294, 'train_loss': 4.49259288969494, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "[I 2025-12-13 05:23:21,324] Trial 8 finished with value: 0.08828522920203735 and parameters: {'lr': 0.0006819165456967618, 'weight_decay': 0.0006027724548797618}. Best is trial 1 with value: 0.0967741935483871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.135818958282471, 'eval_accuracy': 0.08828522920203735, 'eval_runtime': 39.5689, 'eval_samples_per_second': 14.885, 'eval_steps_per_second': 1.87, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.3049, 'grad_norm': 12.312209129333496, 'learning_rate': 1.0278950645399615e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 5.211877822875977, 'eval_accuracy': 0.010186757215619695, 'eval_runtime': 40.428, 'eval_samples_per_second': 14.569, 'eval_steps_per_second': 1.83, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0545, 'grad_norm': 12.611065864562988, 'learning_rate': 7.715316873981659e-06, 'epoch': 2.0}\n",
      "{'eval_loss': 5.117929458618164, 'eval_accuracy': 0.01867572156196944, 'eval_runtime': 40.3046, 'eval_samples_per_second': 14.614, 'eval_steps_per_second': 1.836, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.908, 'grad_norm': 12.874547004699707, 'learning_rate': 5.151683102563702e-06, 'epoch': 3.0}\n",
      "{'eval_loss': 5.0638813972473145, 'eval_accuracy': 0.030560271646859084, 'eval_runtime': 40.2303, 'eval_samples_per_second': 14.641, 'eval_steps_per_second': 1.839, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.8259, 'grad_norm': 13.51242446899414, 'learning_rate': 2.5880493311457464e-06, 'epoch': 4.0}\n",
      "{'eval_loss': 5.04135799407959, 'eval_accuracy': 0.042444821731748725, 'eval_runtime': 40.6549, 'eval_samples_per_second': 14.488, 'eval_steps_per_second': 1.82, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.7768, 'grad_norm': 13.964738845825195, 'learning_rate': 2.4415559727790058e-08, 'epoch': 5.0}\n",
      "{'eval_loss': 5.027364253997803, 'eval_accuracy': 0.044142614601018676, 'eval_runtime': 40.227, 'eval_samples_per_second': 14.642, 'eval_steps_per_second': 1.84, 'epoch': 5.0}\n",
      "{'train_runtime': 1791.7124, 'train_samples_per_second': 9.312, 'train_steps_per_second': 0.293, 'train_loss': 4.9740218098958335, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "[I 2025-12-13 05:53:53,603] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.027364253997803, 'eval_accuracy': 0.044142614601018676, 'eval_runtime': 39.8387, 'eval_samples_per_second': 14.785, 'eval_steps_per_second': 1.857, 'epoch': 5.0}\n",
      "\n",
      "========================================\n",
      "Best accuracy: 9.68%\n",
      "Best learning rate: 0.000588\n",
      "Best weight decay: 0.064405\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return accuracy.compute(predictions=preds, references=p.label_ids)\n",
    "\n",
    "class TimmTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        pixel_values = inputs.get(\"pixel_values\")\n",
    "        labels = inputs.get(\"labels\")\n",
    "        logits = model(pixel_values)\n",
    "        loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, logits) if return_outputs else loss\n",
    "    \n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        pixel_values = inputs.get(\"pixel_values\")\n",
    "        labels = inputs.get(\"labels\")\n",
    "        with torch.no_grad():\n",
    "            logits = model(pixel_values)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "        return (loss, logits, labels)\n",
    "\n",
    "# bayesian optimization with optuna\n",
    "def objective(trial):\n",
    "    # hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    model = timm.create_model(MODEL_NAME, pretrained=False, num_classes=200)\n",
    "    model.to(device)\n",
    "    \n",
    "    run_args = TrainingArguments(\n",
    "        output_dir=f\"{OUTPUT_DIR}/trial_{trial.number}\", \n",
    "        per_device_train_batch_size=32, \n",
    "        num_train_epochs=5,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        warmup_ratio=0.1,\n",
    "        disable_tqdm=True,\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        dataloader_num_workers=0,\n",
    "        remove_unused_columns=False,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "    \n",
    "    trainer = TimmTrainer(\n",
    "        model=model,\n",
    "        args=run_args,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        eval_dataset=dataset[\"validation\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    metrics = trainer.evaluate()\n",
    "    accuracy = metrics[\"eval_accuracy\"]\n",
    "    \n",
    "    trial.report(accuracy, step=5)\n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "        \n",
    "    return accuracy\n",
    "\n",
    "print(\"starting optimization.\")\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"Best accuracy: {study.best_value*100:.2f}%\")\n",
    "print(f\"Best learning rate: {study.best_params['lr']:.6f}\")\n",
    "print(f\"Best weight decay: {study.best_params['weight_decay']:.6f}\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a80576-44a1-4953-a5f1-d1503c9413ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r5/_05_w2k14p728pkkf57ysjg40000gn/T/ipykernel_29741/337494126.py:9: ExperimentalWarning:\n",
      "\n",
      "optuna.visualization.matplotlib._optimization_history.plot_optimization_history is experimental (supported from v2.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r5/_05_w2k14p728pkkf57ysjg40000gn/T/ipykernel_29741/337494126.py:19: ExperimentalWarning:\n",
      "\n",
      "optuna.visualization.matplotlib._param_importances.plot_param_importances is experimental (supported from v2.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots saved successfully (or skipped if invalid).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    plt.figure()\n",
    "    plot_optimization_history(study)\n",
    "    plt.title(\"Optimization History\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"optuna_history.png\")\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Skipping history plot: {e}\")\n",
    "\n",
    "try:\n",
    "    plt.figure()\n",
    "    plot_param_importances(study)\n",
    "    plt.title(\"Hyperparameter Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"optuna_importance.png\")\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Skipping importance plot: {e}\")\n",
    "\n",
    "print(\"Plots saved successfully (or skipped if invalid).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86cafe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 0.18 | Batch: 20 | Curr Loss: 5.3773\n",
      " >> Epoch: 0.37 | Batch: 40 | Curr Loss: 5.3805\n",
      " >> Epoch: 0.56 | Batch: 60 | Curr Loss: 5.2839\n",
      " >> Epoch: 0.75 | Batch: 80 | Curr Loss: 5.1462\n",
      " >> Epoch: 0.94 | Batch: 100 | Curr Loss: 4.9136\n",
      "{'loss': 5.2178, 'grad_norm': 10.284223556518555, 'learning_rate': 0.0001947936507936508, 'epoch': 1.0}\n",
      "{'eval_loss': 5.130096912384033, 'eval_accuracy': 0.013582342954159592, 'eval_runtime': 51.2801, 'eval_samples_per_second': 11.486, 'eval_steps_per_second': 1.443, 'epoch': 1.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   5.2178 | Training Acc:   2.11%\n",
      " Validation Loss: 5.1301       | Validation Acc: 1.36%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 1.18 | Batch: 20 | Curr Loss: 4.9328\n",
      " >> Epoch: 1.37 | Batch: 40 | Curr Loss: 4.8964\n",
      " >> Epoch: 1.56 | Batch: 60 | Curr Loss: 5.1237\n",
      " >> Epoch: 1.75 | Batch: 80 | Curr Loss: 4.8773\n",
      " >> Epoch: 1.94 | Batch: 100 | Curr Loss: 5.0080\n",
      "{'loss': 4.9839, 'grad_norm': 8.275290489196777, 'learning_rate': 0.00039146031746031747, 'epoch': 2.0}\n",
      "{'eval_loss': 4.927040100097656, 'eval_accuracy': 0.027164685908319185, 'eval_runtime': 51.1794, 'eval_samples_per_second': 11.509, 'eval_steps_per_second': 1.446, 'epoch': 2.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   4.9839 | Training Acc:   2.47%\n",
      " Validation Loss: 4.9270       | Validation Acc: 2.72%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 2.18 | Batch: 20 | Curr Loss: 4.8494\n",
      " >> Epoch: 2.37 | Batch: 40 | Curr Loss: 4.7197\n",
      " >> Epoch: 2.56 | Batch: 60 | Curr Loss: 4.9131\n",
      " >> Epoch: 2.75 | Batch: 80 | Curr Loss: 4.5204\n",
      " >> Epoch: 2.94 | Batch: 100 | Curr Loss: 4.3287\n",
      "{'loss': 4.754, 'grad_norm': 10.03862476348877, 'learning_rate': 0.0005881269841269841, 'epoch': 3.0}\n",
      "{'eval_loss': 4.844227313995361, 'eval_accuracy': 0.03395585738539898, 'eval_runtime': 50.5502, 'eval_samples_per_second': 11.652, 'eval_steps_per_second': 1.464, 'epoch': 3.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   4.7540 | Training Acc:   4.49%\n",
      " Validation Loss: 4.8442       | Validation Acc: 3.40%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 3.18 | Batch: 20 | Curr Loss: 4.1451\n",
      " >> Epoch: 3.37 | Batch: 40 | Curr Loss: 4.2590\n",
      " >> Epoch: 3.56 | Batch: 60 | Curr Loss: 4.1918\n",
      " >> Epoch: 3.75 | Batch: 80 | Curr Loss: 4.5747\n",
      " >> Epoch: 3.94 | Batch: 100 | Curr Loss: 3.8969\n",
      "{'loss': 4.3823, 'grad_norm': 8.395546913146973, 'learning_rate': 0.0005683562610229277, 'epoch': 4.0}\n",
      "{'eval_loss': 4.422349452972412, 'eval_accuracy': 0.06112054329371817, 'eval_runtime': 50.0191, 'eval_samples_per_second': 11.776, 'eval_steps_per_second': 1.479, 'epoch': 4.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   4.3823 | Training Acc:   7.08%\n",
      " Validation Loss: 4.4223       | Validation Acc: 6.11%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 4.18 | Batch: 20 | Curr Loss: 3.8817\n",
      " >> Epoch: 4.37 | Batch: 40 | Curr Loss: 3.8333\n",
      " >> Epoch: 4.56 | Batch: 60 | Curr Loss: 3.9109\n",
      " >> Epoch: 4.75 | Batch: 80 | Curr Loss: 4.1220\n",
      " >> Epoch: 4.94 | Batch: 100 | Curr Loss: 3.9872\n",
      "{'loss': 3.9773, 'grad_norm': 8.08813190460205, 'learning_rate': 0.0005465044091710759, 'epoch': 5.0}\n",
      "{'eval_loss': 4.1935577392578125, 'eval_accuracy': 0.07640067911714771, 'eval_runtime': 50.5166, 'eval_samples_per_second': 11.66, 'eval_steps_per_second': 1.465, 'epoch': 5.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   3.9773 | Training Acc:   10.97%\n",
      " Validation Loss: 4.1936       | Validation Acc: 7.64%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 5.18 | Batch: 20 | Curr Loss: 3.4830\n",
      " >> Epoch: 5.37 | Batch: 40 | Curr Loss: 3.6370\n",
      " >> Epoch: 5.56 | Batch: 60 | Curr Loss: 4.1356\n",
      " >> Epoch: 5.75 | Batch: 80 | Curr Loss: 4.0558\n",
      " >> Epoch: 5.94 | Batch: 100 | Curr Loss: 3.3267\n",
      "{'loss': 3.622, 'grad_norm': 10.726155281066895, 'learning_rate': 0.000524652557319224, 'epoch': 6.0}\n",
      "{'eval_loss': 4.050048828125, 'eval_accuracy': 0.10865874363327674, 'eval_runtime': 39.7396, 'eval_samples_per_second': 14.821, 'eval_steps_per_second': 1.862, 'epoch': 6.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   3.6220 | Training Acc:   16.55%\n",
      " Validation Loss: 4.0500       | Validation Acc: 10.87%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 6.18 | Batch: 20 | Curr Loss: 3.1074\n",
      " >> Epoch: 6.37 | Batch: 40 | Curr Loss: 3.4686\n",
      " >> Epoch: 6.56 | Batch: 60 | Curr Loss: 3.1930\n",
      " >> Epoch: 6.75 | Batch: 80 | Curr Loss: 3.4166\n",
      " >> Epoch: 6.94 | Batch: 100 | Curr Loss: 2.7455\n",
      "{'loss': 3.3184, 'grad_norm': 14.633980751037598, 'learning_rate': 0.0005028007054673722, 'epoch': 7.0}\n",
      "{'eval_loss': 3.945162773132324, 'eval_accuracy': 0.12224108658743633, 'eval_runtime': 40.5142, 'eval_samples_per_second': 14.538, 'eval_steps_per_second': 1.827, 'epoch': 7.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   3.3184 | Training Acc:   20.14%\n",
      " Validation Loss: 3.9452       | Validation Acc: 12.22%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 7.18 | Batch: 20 | Curr Loss: 2.7180\n",
      " >> Epoch: 7.37 | Batch: 40 | Curr Loss: 3.5422\n",
      " >> Epoch: 7.56 | Batch: 60 | Curr Loss: 3.5168\n",
      " >> Epoch: 7.75 | Batch: 80 | Curr Loss: 2.7648\n",
      " >> Epoch: 7.94 | Batch: 100 | Curr Loss: 2.7176\n",
      "{'loss': 3.0321, 'grad_norm': 9.29461669921875, 'learning_rate': 0.00048094885361552026, 'epoch': 8.0}\n",
      "{'eval_loss': 3.838784694671631, 'eval_accuracy': 0.1307300509337861, 'eval_runtime': 40.1665, 'eval_samples_per_second': 14.664, 'eval_steps_per_second': 1.842, 'epoch': 8.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   3.0321 | Training Acc:   25.35%\n",
      " Validation Loss: 3.8388       | Validation Acc: 13.07%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 8.18 | Batch: 20 | Curr Loss: 2.7043\n",
      " >> Epoch: 8.37 | Batch: 40 | Curr Loss: 2.5600\n",
      " >> Epoch: 8.56 | Batch: 60 | Curr Loss: 3.0015\n",
      " >> Epoch: 8.75 | Batch: 80 | Curr Loss: 2.8091\n",
      " >> Epoch: 8.94 | Batch: 100 | Curr Loss: 2.7317\n",
      "{'loss': 2.7037, 'grad_norm': 12.002574920654297, 'learning_rate': 0.0004590970017636685, 'epoch': 9.0}\n",
      "{'eval_loss': 3.8045663833618164, 'eval_accuracy': 0.15789473684210525, 'eval_runtime': 40.0145, 'eval_samples_per_second': 14.72, 'eval_steps_per_second': 1.849, 'epoch': 9.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   2.7037 | Training Acc:   31.33%\n",
      " Validation Loss: 3.8046       | Validation Acc: 15.79%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 9.18 | Batch: 20 | Curr Loss: 3.0540\n",
      " >> Epoch: 9.37 | Batch: 40 | Curr Loss: 2.0197\n",
      " >> Epoch: 9.56 | Batch: 60 | Curr Loss: 2.6784\n",
      " >> Epoch: 9.75 | Batch: 80 | Curr Loss: 2.1509\n",
      " >> Epoch: 9.94 | Batch: 100 | Curr Loss: 2.6214\n",
      "{'loss': 2.4116, 'grad_norm': 15.873795509338379, 'learning_rate': 0.0004372451499118166, 'epoch': 10.0}\n",
      "{'eval_loss': 3.768836498260498, 'eval_accuracy': 0.15789473684210525, 'eval_runtime': 39.7963, 'eval_samples_per_second': 14.8, 'eval_steps_per_second': 1.859, 'epoch': 10.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   2.4116 | Training Acc:   36.45%\n",
      " Validation Loss: 3.7688       | Validation Acc: 15.79%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 10.18 | Batch: 20 | Curr Loss: 2.1130\n",
      " >> Epoch: 10.37 | Batch: 40 | Curr Loss: 1.9455\n",
      " >> Epoch: 10.56 | Batch: 60 | Curr Loss: 1.8883\n",
      " >> Epoch: 10.75 | Batch: 80 | Curr Loss: 1.9698\n",
      " >> Epoch: 10.94 | Batch: 100 | Curr Loss: 1.8928\n",
      "{'loss': 2.0707, 'grad_norm': 11.393025398254395, 'learning_rate': 0.00041539329805996474, 'epoch': 11.0}\n",
      "{'eval_loss': 3.6934709548950195, 'eval_accuracy': 0.19524617996604415, 'eval_runtime': 40.2741, 'eval_samples_per_second': 14.625, 'eval_steps_per_second': 1.837, 'epoch': 11.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   2.0707 | Training Acc:   45.07%\n",
      " Validation Loss: 3.6935       | Validation Acc: 19.52%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 11.18 | Batch: 20 | Curr Loss: 1.5515\n",
      " >> Epoch: 11.37 | Batch: 40 | Curr Loss: 1.8391\n",
      " >> Epoch: 11.56 | Batch: 60 | Curr Loss: 2.0574\n",
      " >> Epoch: 11.75 | Batch: 80 | Curr Loss: 2.0720\n",
      " >> Epoch: 11.94 | Batch: 100 | Curr Loss: 1.8555\n",
      "{'loss': 1.7389, 'grad_norm': 16.961502075195312, 'learning_rate': 0.0003935414462081129, 'epoch': 12.0}\n",
      "{'eval_loss': 3.720306873321533, 'eval_accuracy': 0.19185059422750425, 'eval_runtime': 40.0942, 'eval_samples_per_second': 14.69, 'eval_steps_per_second': 1.846, 'epoch': 12.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   1.7389 | Training Acc:   52.71%\n",
      " Validation Loss: 3.7203       | Validation Acc: 19.19%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 12.18 | Batch: 20 | Curr Loss: 1.3650\n",
      " >> Epoch: 12.37 | Batch: 40 | Curr Loss: 1.2278\n",
      " >> Epoch: 12.56 | Batch: 60 | Curr Loss: 1.4190\n",
      " >> Epoch: 12.75 | Batch: 80 | Curr Loss: 1.4284\n",
      " >> Epoch: 12.94 | Batch: 100 | Curr Loss: 1.5411\n",
      "{'loss': 1.4315, 'grad_norm': 22.982240676879883, 'learning_rate': 0.00037168959435626106, 'epoch': 13.0}\n",
      "{'eval_loss': 3.8373732566833496, 'eval_accuracy': 0.21731748726655348, 'eval_runtime': 40.5991, 'eval_samples_per_second': 14.508, 'eval_steps_per_second': 1.823, 'epoch': 13.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   1.4315 | Training Acc:   60.96%\n",
      " Validation Loss: 3.8374       | Validation Acc: 21.73%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 13.18 | Batch: 20 | Curr Loss: 0.6224\n",
      " >> Epoch: 13.37 | Batch: 40 | Curr Loss: 0.9201\n",
      " >> Epoch: 13.56 | Batch: 60 | Curr Loss: 1.2351\n",
      " >> Epoch: 13.75 | Batch: 80 | Curr Loss: 1.4629\n",
      " >> Epoch: 13.94 | Batch: 100 | Curr Loss: 1.2607\n",
      "{'loss': 1.1369, 'grad_norm': 25.78968048095703, 'learning_rate': 0.00034983774250440917, 'epoch': 14.0}\n",
      "{'eval_loss': 3.9683172702789307, 'eval_accuracy': 0.200339558573854, 'eval_runtime': 40.3588, 'eval_samples_per_second': 14.594, 'eval_steps_per_second': 1.834, 'epoch': 14.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   1.1369 | Training Acc:   69.83%\n",
      " Validation Loss: 3.9683       | Validation Acc: 20.03%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 14.18 | Batch: 20 | Curr Loss: 0.8004\n",
      " >> Epoch: 14.37 | Batch: 40 | Curr Loss: 0.8045\n",
      " >> Epoch: 14.56 | Batch: 60 | Curr Loss: 0.6726\n",
      " >> Epoch: 14.75 | Batch: 80 | Curr Loss: 0.9072\n",
      " >> Epoch: 14.94 | Batch: 100 | Curr Loss: 0.8003\n",
      "{'loss': 0.8623, 'grad_norm': 15.766268730163574, 'learning_rate': 0.00032798589065255733, 'epoch': 15.0}\n",
      "{'eval_loss': 3.8935000896453857, 'eval_accuracy': 0.23938879456706283, 'eval_runtime': 40.6202, 'eval_samples_per_second': 14.5, 'eval_steps_per_second': 1.822, 'epoch': 15.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.8623 | Training Acc:   77.63%\n",
      " Validation Loss: 3.8935       | Validation Acc: 23.94%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 15.18 | Batch: 20 | Curr Loss: 0.5203\n",
      " >> Epoch: 15.37 | Batch: 40 | Curr Loss: 0.4531\n",
      " >> Epoch: 15.56 | Batch: 60 | Curr Loss: 0.9423\n",
      " >> Epoch: 15.75 | Batch: 80 | Curr Loss: 1.0892\n",
      " >> Epoch: 15.94 | Batch: 100 | Curr Loss: 0.5968\n",
      "{'loss': 0.65, 'grad_norm': 45.053955078125, 'learning_rate': 0.0003061340388007055, 'epoch': 16.0}\n",
      "{'eval_loss': 4.2083635330200195, 'eval_accuracy': 0.1969439728353141, 'eval_runtime': 38.9639, 'eval_samples_per_second': 15.117, 'eval_steps_per_second': 1.899, 'epoch': 16.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.6500 | Training Acc:   83.86%\n",
      " Validation Loss: 4.2084       | Validation Acc: 19.69%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 16.18 | Batch: 20 | Curr Loss: 0.3888\n",
      " >> Epoch: 16.37 | Batch: 40 | Curr Loss: 0.2316\n",
      " >> Epoch: 16.56 | Batch: 60 | Curr Loss: 0.6525\n",
      " >> Epoch: 16.75 | Batch: 80 | Curr Loss: 0.6945\n",
      " >> Epoch: 16.94 | Batch: 100 | Curr Loss: 0.7494\n",
      "{'loss': 0.4624, 'grad_norm': 11.883749008178711, 'learning_rate': 0.0002842821869488536, 'epoch': 17.0}\n",
      "{'eval_loss': 4.194108009338379, 'eval_accuracy': 0.22071307300509338, 'eval_runtime': 38.7248, 'eval_samples_per_second': 15.21, 'eval_steps_per_second': 1.911, 'epoch': 17.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.4624 | Training Acc:   89.64%\n",
      " Validation Loss: 4.1941       | Validation Acc: 22.07%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 17.18 | Batch: 20 | Curr Loss: 0.3237\n",
      " >> Epoch: 17.37 | Batch: 40 | Curr Loss: 0.3824\n",
      " >> Epoch: 17.56 | Batch: 60 | Curr Loss: 0.2998\n",
      " >> Epoch: 17.75 | Batch: 80 | Curr Loss: 0.1627\n",
      " >> Epoch: 17.94 | Batch: 100 | Curr Loss: 0.3493\n",
      "{'loss': 0.3135, 'grad_norm': 14.126153945922852, 'learning_rate': 0.00026243033509700176, 'epoch': 18.0}\n",
      "{'eval_loss': 4.239490032196045, 'eval_accuracy': 0.21731748726655348, 'eval_runtime': 39.3812, 'eval_samples_per_second': 14.956, 'eval_steps_per_second': 1.879, 'epoch': 18.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.3135 | Training Acc:   93.84%\n",
      " Validation Loss: 4.2395       | Validation Acc: 21.73%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 18.18 | Batch: 20 | Curr Loss: 0.1911\n",
      " >> Epoch: 18.37 | Batch: 40 | Curr Loss: 0.1680\n",
      " >> Epoch: 18.56 | Batch: 60 | Curr Loss: 0.1914\n",
      " >> Epoch: 18.75 | Batch: 80 | Curr Loss: 0.1563\n",
      " >> Epoch: 18.94 | Batch: 100 | Curr Loss: 0.1801\n",
      "{'loss': 0.219, 'grad_norm': 6.319021701812744, 'learning_rate': 0.00024057848324514992, 'epoch': 19.0}\n",
      "{'eval_loss': 4.304888725280762, 'eval_accuracy': 0.22750424448217318, 'eval_runtime': 40.7165, 'eval_samples_per_second': 14.466, 'eval_steps_per_second': 1.817, 'epoch': 19.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.2190 | Training Acc:   96.49%\n",
      " Validation Loss: 4.3049       | Validation Acc: 22.75%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 19.18 | Batch: 20 | Curr Loss: 0.1677\n",
      " >> Epoch: 19.37 | Batch: 40 | Curr Loss: 0.1382\n",
      " >> Epoch: 19.56 | Batch: 60 | Curr Loss: 0.1251\n",
      " >> Epoch: 19.75 | Batch: 80 | Curr Loss: 0.2452\n",
      " >> Epoch: 19.94 | Batch: 100 | Curr Loss: 0.2391\n",
      "{'loss': 0.163, 'grad_norm': 11.006569862365723, 'learning_rate': 0.00021872663139329806, 'epoch': 20.0}\n",
      "{'eval_loss': 4.4433112144470215, 'eval_accuracy': 0.23599320882852293, 'eval_runtime': 38.9619, 'eval_samples_per_second': 15.117, 'eval_steps_per_second': 1.899, 'epoch': 20.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.1630 | Training Acc:   97.35%\n",
      " Validation Loss: 4.4433       | Validation Acc: 23.60%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 20.18 | Batch: 20 | Curr Loss: 0.0818\n",
      " >> Epoch: 20.37 | Batch: 40 | Curr Loss: 0.1103\n",
      " >> Epoch: 20.56 | Batch: 60 | Curr Loss: 0.1260\n",
      " >> Epoch: 20.75 | Batch: 80 | Curr Loss: 0.1257\n",
      " >> Epoch: 20.94 | Batch: 100 | Curr Loss: 0.1480\n",
      "{'loss': 0.1056, 'grad_norm': 4.885464668273926, 'learning_rate': 0.00019687477954144622, 'epoch': 21.0}\n",
      "{'eval_loss': 4.59205961227417, 'eval_accuracy': 0.21731748726655348, 'eval_runtime': 40.2525, 'eval_samples_per_second': 14.633, 'eval_steps_per_second': 1.838, 'epoch': 21.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.1056 | Training Acc:   98.51%\n",
      " Validation Loss: 4.5921       | Validation Acc: 21.73%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 21.18 | Batch: 20 | Curr Loss: 0.0576\n",
      " >> Epoch: 21.37 | Batch: 40 | Curr Loss: 0.0737\n",
      " >> Epoch: 21.56 | Batch: 60 | Curr Loss: 0.0560\n",
      " >> Epoch: 21.75 | Batch: 80 | Curr Loss: 0.0348\n",
      " >> Epoch: 21.94 | Batch: 100 | Curr Loss: 0.0772\n",
      "{'loss': 0.0735, 'grad_norm': 36.170257568359375, 'learning_rate': 0.00017502292768959435, 'epoch': 22.0}\n",
      "{'eval_loss': 4.522821426391602, 'eval_accuracy': 0.23089983022071306, 'eval_runtime': 38.8417, 'eval_samples_per_second': 15.164, 'eval_steps_per_second': 1.905, 'epoch': 22.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.0735 | Training Acc:   99.15%\n",
      " Validation Loss: 4.5228       | Validation Acc: 23.09%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 22.18 | Batch: 20 | Curr Loss: 0.0395\n",
      " >> Epoch: 22.37 | Batch: 40 | Curr Loss: 0.0300\n",
      " >> Epoch: 22.56 | Batch: 60 | Curr Loss: 0.0474\n",
      " >> Epoch: 22.75 | Batch: 80 | Curr Loss: 0.0203\n",
      " >> Epoch: 22.94 | Batch: 100 | Curr Loss: 0.0610\n",
      "{'loss': 0.0467, 'grad_norm': 7.824173450469971, 'learning_rate': 0.0001531710758377425, 'epoch': 23.0}\n",
      "{'eval_loss': 4.717574596405029, 'eval_accuracy': 0.24448217317487267, 'eval_runtime': 38.8327, 'eval_samples_per_second': 15.168, 'eval_steps_per_second': 1.906, 'epoch': 23.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.0467 | Training Acc:   99.35%\n",
      " Validation Loss: 4.7176       | Validation Acc: 24.45%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 23.18 | Batch: 20 | Curr Loss: 0.0132\n",
      " >> Epoch: 23.37 | Batch: 40 | Curr Loss: 0.0181\n",
      " >> Epoch: 23.56 | Batch: 60 | Curr Loss: 0.0580\n",
      " >> Epoch: 23.75 | Batch: 80 | Curr Loss: 0.0455\n",
      " >> Epoch: 23.94 | Batch: 100 | Curr Loss: 0.0194\n",
      "{'loss': 0.0277, 'grad_norm': 2.1753718852996826, 'learning_rate': 0.00013131922398589065, 'epoch': 24.0}\n",
      "{'eval_loss': 4.52877140045166, 'eval_accuracy': 0.24448217317487267, 'eval_runtime': 38.5163, 'eval_samples_per_second': 15.292, 'eval_steps_per_second': 1.921, 'epoch': 24.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.0277 | Training Acc:   99.70%\n",
      " Validation Loss: 4.5288       | Validation Acc: 24.45%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 24.18 | Batch: 20 | Curr Loss: 0.0051\n",
      " >> Epoch: 24.37 | Batch: 40 | Curr Loss: 0.0274\n",
      " >> Epoch: 24.56 | Batch: 60 | Curr Loss: 0.0064\n",
      " >> Epoch: 24.75 | Batch: 80 | Curr Loss: 0.0106\n",
      " >> Epoch: 24.94 | Batch: 100 | Curr Loss: 0.0209\n",
      "{'loss': 0.0122, 'grad_norm': 0.6602526307106018, 'learning_rate': 0.00010946737213403881, 'epoch': 25.0}\n",
      "{'eval_loss': 4.658316612243652, 'eval_accuracy': 0.26485568760611206, 'eval_runtime': 39.1368, 'eval_samples_per_second': 15.05, 'eval_steps_per_second': 1.891, 'epoch': 25.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.0122 | Training Acc:   99.88%\n",
      " Validation Loss: 4.6583       | Validation Acc: 26.49%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 25.18 | Batch: 20 | Curr Loss: 0.0062\n",
      " >> Epoch: 25.37 | Batch: 40 | Curr Loss: 0.0092\n",
      " >> Epoch: 25.56 | Batch: 60 | Curr Loss: 0.0040\n",
      " >> Epoch: 25.75 | Batch: 80 | Curr Loss: 0.0040\n",
      " >> Epoch: 25.94 | Batch: 100 | Curr Loss: 0.0065\n",
      "{'loss': 0.0058, 'grad_norm': 3.255305767059326, 'learning_rate': 8.761552028218696e-05, 'epoch': 26.0}\n",
      "{'eval_loss': 4.678788661956787, 'eval_accuracy': 0.266553480475382, 'eval_runtime': 38.8178, 'eval_samples_per_second': 15.173, 'eval_steps_per_second': 1.906, 'epoch': 26.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.0058 | Training Acc:   100.00%\n",
      " Validation Loss: 4.6788       | Validation Acc: 26.66%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 26.18 | Batch: 20 | Curr Loss: 0.0025\n",
      " >> Epoch: 26.37 | Batch: 40 | Curr Loss: 0.0039\n",
      " >> Epoch: 26.56 | Batch: 60 | Curr Loss: 0.0032\n",
      " >> Epoch: 26.75 | Batch: 80 | Curr Loss: 0.0054\n",
      " >> Epoch: 26.94 | Batch: 100 | Curr Loss: 0.0028\n",
      "{'loss': 0.0042, 'grad_norm': 0.3624430298805237, 'learning_rate': 6.57636684303351e-05, 'epoch': 27.0}\n",
      "{'eval_loss': 4.6009416580200195, 'eval_accuracy': 0.2529711375212224, 'eval_runtime': 38.7161, 'eval_samples_per_second': 15.213, 'eval_steps_per_second': 1.911, 'epoch': 27.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.0042 | Training Acc:   100.00%\n",
      " Validation Loss: 4.6009       | Validation Acc: 25.30%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 27.18 | Batch: 20 | Curr Loss: 0.0021\n",
      " >> Epoch: 27.37 | Batch: 40 | Curr Loss: 0.0053\n",
      " >> Epoch: 27.56 | Batch: 60 | Curr Loss: 0.0037\n",
      " >> Epoch: 27.75 | Batch: 80 | Curr Loss: 0.0015\n",
      " >> Epoch: 27.94 | Batch: 100 | Curr Loss: 0.0022\n",
      "{'loss': 0.0035, 'grad_norm': 0.3796064555644989, 'learning_rate': 4.3911816578483244e-05, 'epoch': 28.0}\n",
      "{'eval_loss': 4.644228458404541, 'eval_accuracy': 0.2699490662139219, 'eval_runtime': 39.1944, 'eval_samples_per_second': 15.028, 'eval_steps_per_second': 1.888, 'epoch': 28.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.0035 | Training Acc:   100.00%\n",
      " Validation Loss: 4.6442       | Validation Acc: 26.99%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 28.18 | Batch: 20 | Curr Loss: 0.0023\n",
      " >> Epoch: 28.37 | Batch: 40 | Curr Loss: 0.0017\n",
      " >> Epoch: 28.56 | Batch: 60 | Curr Loss: 0.0027\n",
      " >> Epoch: 28.75 | Batch: 80 | Curr Loss: 0.0030\n",
      " >> Epoch: 28.94 | Batch: 100 | Curr Loss: 0.0015\n",
      "{'loss': 0.0026, 'grad_norm': 0.7686575055122375, 'learning_rate': 2.2059964726631395e-05, 'epoch': 29.0}\n",
      "{'eval_loss': 4.679091453552246, 'eval_accuracy': 0.2699490662139219, 'eval_runtime': 39.1696, 'eval_samples_per_second': 15.037, 'eval_steps_per_second': 1.889, 'epoch': 29.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.0026 | Training Acc:   100.00%\n",
      " Validation Loss: 4.6791       | Validation Acc: 26.99%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 29.18 | Batch: 20 | Curr Loss: 0.0011\n",
      " >> Epoch: 29.37 | Batch: 40 | Curr Loss: 0.0011\n",
      " >> Epoch: 29.56 | Batch: 60 | Curr Loss: 0.0030\n",
      " >> Epoch: 29.75 | Batch: 80 | Curr Loss: 0.0013\n",
      " >> Epoch: 29.94 | Batch: 100 | Curr Loss: 0.0020\n",
      "{'loss': 0.0046, 'grad_norm': 16.601381301879883, 'learning_rate': 2.0811287477954147e-07, 'epoch': 30.0}\n",
      "{'eval_loss': 4.657985210418701, 'eval_accuracy': 0.2699490662139219, 'eval_runtime': 39.2359, 'eval_samples_per_second': 15.012, 'eval_steps_per_second': 1.886, 'epoch': 30.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.0046 | Training Acc:   99.89%\n",
      " Validation Loss: 4.6580       | Validation Acc: 26.99%\n",
      "================================================================================\n",
      "\n",
      "{'train_runtime': 10929.6477, 'train_samples_per_second': 9.159, 'train_steps_per_second': 0.288, 'train_loss': 1.5912546919830262, 'epoch': 30.0}\n",
      "Best model saved.\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "model = timm.create_model(\n",
    "    MODEL_NAME, \n",
    "    pretrained=False, \n",
    "    num_classes=200 \n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "class TimmTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.epoch_train_loss = 0.0\n",
    "        self.epoch_train_acc = 0.0\n",
    "        self.epoch_steps = 0\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        pixel_values = inputs.get(\"pixel_values\")\n",
    "        labels = inputs.get(\"labels\")\n",
    "        \n",
    "        logits = model(pixel_values)\n",
    "        loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits, labels)\n",
    "        \n",
    "        if model.training:\n",
    "            with torch.no_grad():\n",
    "                preds = torch.argmax(logits, dim=-1)\n",
    "                acc = (preds == labels).float().mean().item()\n",
    "                \n",
    "                self.epoch_train_loss += loss.item()\n",
    "                self.epoch_train_acc += acc\n",
    "                self.epoch_steps += 1\n",
    "                \n",
    "                if self.epoch_steps % 20 == 0:\n",
    "                    current_epoch_float = self.state.epoch if self.state.epoch is not None else 0\n",
    "                    print(f\" >> Epoch: {current_epoch_float:.2f} | Batch: {self.epoch_steps} | Curr Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        return (loss, logits) if return_outputs else loss\n",
    "    \n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        pixel_values = inputs.get(\"pixel_values\")\n",
    "        labels = inputs.get(\"labels\")\n",
    "        with torch.no_grad():\n",
    "            logits = model(pixel_values)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "        if prediction_loss_only:\n",
    "            return (loss, None, None)\n",
    "        return (loss, logits, labels)\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "        metrics = super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
    "        \n",
    "        avg_train_loss = self.epoch_train_loss / self.epoch_steps if self.epoch_steps > 0 else 0\n",
    "        avg_train_acc = self.epoch_train_acc / self.epoch_steps if self.epoch_steps > 0 else 0\n",
    "        \n",
    "        val_loss = metrics.get(f\"{metric_key_prefix}_loss\", 0.0)\n",
    "        val_acc = metrics.get(f\"{metric_key_prefix}_accuracy\", 0.0)\n",
    "        \n",
    "        epoch_num = int(self.state.epoch) if self.state.epoch else 0\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\" Training Loss:   {avg_train_loss:.4f} | Training Acc:   {avg_train_acc*100:.2f}%\")\n",
    "        print(f\" Validation Loss: {val_loss:.4f}       | Validation Acc: {val_acc*100:.2f}%\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        # resetting counters\n",
    "        self.epoch_train_loss = 0.0\n",
    "        self.epoch_train_acc = 0.0\n",
    "        self.epoch_steps = 0\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "# accuracy metrics:\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return accuracy.compute(predictions=preds, references=p.label_ids)\n",
    "\n",
    "# training, updated from Optuna\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=32, \n",
    "    num_train_epochs=30,\n",
    "    learning_rate=5.9e-4,\n",
    "    weight_decay=0.065,\n",
    "    warmup_ratio=0.1,\n",
    "    \n",
    "    load_best_model_at_end=True,     \n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=1,\n",
    "    seed=42,\n",
    "    \n",
    "    disable_tqdm=True, # for now bc i dont like it - Julia\n",
    "    \n",
    "    logging_strategy=\"epoch\", \n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    \n",
    "    dataloader_num_workers=0,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# the actual training\n",
    "trainer = TimmTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"final_new_model\")\n",
    "print(\"Best model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "433eb3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous best model to establish baseline.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning:\n",
      "\n",
      "'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (NoneType, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 22\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# simple trainer just for evaluation\u001b[39;00m\n\u001b[1;32m     16\u001b[0m eval_trainer \u001b[38;5;241m=\u001b[39m TimmTrainer(\n\u001b[1;32m     17\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     18\u001b[0m     args\u001b[38;5;241m=\u001b[39mTrainingArguments(output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_eval\u001b[39m\u001b[38;5;124m\"\u001b[39m, report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, per_device_eval_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m),\n\u001b[1;32m     19\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mdataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     20\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m base_metrics \u001b[38;5;241m=\u001b[39m eval_trainer\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m     23\u001b[0m global_best_acc \u001b[38;5;241m=\u001b[39m base_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent Best Accuracy (Seed 42): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mglobal_best_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 56\u001b[0m, in \u001b[0;36mTimmTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, metric_key_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 56\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mevaluate(eval_dataset, ignore_keys, metric_key_prefix)\n\u001b[1;32m     58\u001b[0m     avg_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_steps \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     59\u001b[0m     avg_train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_train_acc \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_steps \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/trainer.py:4489\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4486\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   4488\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4489\u001b[0m output \u001b[38;5;241m=\u001b[39m eval_loop(\n\u001b[1;32m   4490\u001b[0m     eval_dataloader,\n\u001b[1;32m   4491\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4492\u001b[0m     \u001b[38;5;66;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;00m\n\u001b[1;32m   4493\u001b[0m     \u001b[38;5;66;03m# self.args.prediction_loss_only\u001b[39;00m\n\u001b[1;32m   4494\u001b[0m     prediction_loss_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4495\u001b[0m     ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys,\n\u001b[1;32m   4496\u001b[0m     metric_key_prefix\u001b[38;5;241m=\u001b[39mmetric_key_prefix,\n\u001b[1;32m   4497\u001b[0m )\n\u001b[1;32m   4499\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   4500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/trainer.py:4685\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4682\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   4684\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 4685\u001b[0m losses, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_step(model, inputs, prediction_loss_only, ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys)\n\u001b[1;32m   4686\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4687\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   4688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4689\u001b[0m )\n",
      "Cell \u001b[0;32mIn[15], line 46\u001b[0m, in \u001b[0;36mTimmTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m     44\u001b[0m labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 46\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model(pixel_values)\n\u001b[1;32m     47\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/timm/models/maxxvit.py:1574\u001b[0m, in \u001b[0;36mMaxxVit.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m-> 1574\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_features(x)\n\u001b[1;32m   1575\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[1;32m   1576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/timm/models/maxxvit.py:1565\u001b[0m, in \u001b[0;36mMaxxVit.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m-> 1565\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstem(x)\n\u001b[1;32m   1566\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages(x)\n\u001b[1;32m   1567\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/timm/models/maxxvit.py:1312\u001b[0m, in \u001b[0;36mStem.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m-> 1312\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m   1313\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x)\n\u001b[1;32m   1314\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/conv.py:548\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/conv.py:543\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    533\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    542\u001b[0m     )\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    545\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (NoneType, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!NoneType!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n"
     ]
    }
   ],
   "source": [
    "import safetensors.torch\n",
    "\n",
    "# check the accuracy of the model we just saved (seed 42) to know what to beat\n",
    "print(\"Loading previous best model to establish baseline.\")\n",
    "model = timm.create_model(MODEL_NAME, pretrained=False, num_classes=200)\n",
    "\n",
    "try:\n",
    "    state_dict = safetensors.torch.load_file(\"final_new_model/model.safetensors\", device=device)\n",
    "except FileNotFoundError:\n",
    "    state_dict = safetensors.torch.load_file(f\"{OUTPUT_DIR}/final_new_model/model.safetensors\", device=device)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "\n",
    "# simple trainer just for evaluation\n",
    "eval_trainer = TimmTrainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(output_dir=\"temp_eval\", report_to=\"none\", per_device_eval_batch_size=32),\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "base_metrics = eval_trainer.evaluate()\n",
    "global_best_acc = base_metrics[\"eval_accuracy\"]\n",
    "print(f\"Current Best Accuracy (Seed 42): {global_best_acc*100:.2f}%\")\n",
    "\n",
    "# now run the other seeds\n",
    "other_seeds = [1, 100]\n",
    "\n",
    "for seed in other_seeds:\n",
    "    print(f\"\\n{'='*20} Running Seed {seed} {'='*20}\")\n",
    "    set_seed(seed)\n",
    "\n",
    "    model = timm.create_model(\n",
    "        MODEL_NAME, \n",
    "        pretrained=False, \n",
    "        num_classes=200 \n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    # same args as before\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"{OUTPUT_DIR}/seed_{seed}\",\n",
    "        per_device_train_batch_size=32, \n",
    "        num_train_epochs=30,\n",
    "        learning_rate=5.9e-4,     \n",
    "        weight_decay=0.065,       \n",
    "        warmup_ratio=0.1,\n",
    "        \n",
    "        load_best_model_at_end=True,     \n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        save_total_limit=1,\n",
    "        seed=seed,\n",
    "        \n",
    "        disable_tqdm=True,\n",
    "        logging_strategy=\"epoch\", \n",
    "        save_strategy=\"epoch\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        \n",
    "        dataloader_num_workers=0,\n",
    "        remove_unused_columns=False,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    trainer = TimmTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        eval_dataset=dataset[\"validation\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    # check if this seed beat the previous best\n",
    "    metrics = trainer.evaluate()\n",
    "    current_acc = metrics[\"eval_accuracy\"]\n",
    "    print(f\"Seed {seed} Accuracy: {current_acc*100:.2f}%\")\n",
    "    \n",
    "    if current_acc > global_best_acc:\n",
    "        print(f\"New best found! ({current_acc*100:.2f}% > {global_best_acc*100:.2f}%) Overwriting final model...\")\n",
    "        global_best_acc = current_acc\n",
    "        trainer.save_model(\"final_new_model\") # Saves the new best model\n",
    "    else:\n",
    "        print(f\"Did not beat current best ({global_best_acc*100:.2f}%). Keeping previous model.\")\n",
    "\n",
    "print(f\"Final Experiment Finished. Best model saved with accuracy: {global_best_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ab7db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
