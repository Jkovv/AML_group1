{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e521e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install timm\n",
    "#!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c506a5cf",
   "metadata": {},
   "source": [
    "# new model - coatnet\n",
    "hybrid architecture - Convolution + Attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e284eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_from_disk\n",
    "import timm\n",
    "from transformers import (\n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "from torchvision.transforms import (\n",
    "    Compose, Resize, CenterCrop, ToTensor, Normalize, \n",
    "    RandomHorizontalFlip, RandomResizedCrop\n",
    ")\n",
    "\n",
    "DATA_PATH = \"processed_bird_data\"\n",
    "OUTPUT_DIR = \"new_model_checkpoints\"\n",
    "\n",
    "# Using 'coatnet_0_rw_224' model, with '0' to use the smallest version to avoid overfitting:\n",
    "MODEL_NAME = \"coatnet_0_rw_224\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4adfe7b",
   "metadata": {},
   "source": [
    "Applying Aggressive Data Augmentation to prevent overfitting:\n",
    "\n",
    "1. Does random resize/zoom (scale 0.8â€“1.0). Forces the model to recognize a bird by looking at its specific feature (e.g. the head, wing, etc.) instead of the background (e.g. tress).\n",
    "2. Incorporates horizontal flipping to double the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07295e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset.\n",
      "Applying transforms and removing raw images...\n",
      "Data ready.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset.\")\n",
    "dataset = load_from_disk(DATA_PATH)\n",
    "\n",
    "# transformations:\n",
    "# normalization of values for ImageNet:\n",
    "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# training: random crops + flips (noise helps it learn):\n",
    "_train_transforms = Compose([\n",
    "    RandomResizedCrop(224, scale=(0.8, 1.0)), \n",
    "    RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# validation - deterministic center crop\n",
    "_val_transforms = Compose([\n",
    "    Resize(256),\n",
    "    CenterCrop(224),\n",
    "    ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "def train_transforms(batch):\n",
    "    batch[\"pixel_values\"] = [_train_transforms(image.convert(\"RGB\")) for image in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "def val_transforms(batch):\n",
    "    batch[\"pixel_values\"] = [_val_transforms(image.convert(\"RGB\")) for image in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "# using .map() instead of .set_transform() because set_transform keeps the original columns accessible, and we want to delete those raw pngs to avoid program crashing.\n",
    "print(\"Applying transforms and removing raw images...\")\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].map(\n",
    "    train_transforms, \n",
    "    batched=True, \n",
    "    remove_columns=[\"image\"]\n",
    ")\n",
    "\n",
    "dataset[\"validation\"] = dataset[\"validation\"].map(\n",
    "    val_transforms, \n",
    "    batched=True, \n",
    "    remove_columns=[\"image\"]\n",
    ")\n",
    "\n",
    "print(\"Data ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66360a0",
   "metadata": {},
   "source": [
    "# Training\n",
    "Initializing CoAtNet model with random weights, no pretraining. \n",
    "\n",
    "It uses standard Convolutional layers in the early stages to extract low-level features (edges, textures), and then uses Transformer layers in the final stages to understand the global shape of the bird. Also:\n",
    "\n",
    "1. High learning rate;\n",
    "2. 15 epochs;\n",
    "3. Uses regularization to prevent the model from memorizing the training images.\n",
    "\n",
    "(using TimmTrainer class as the timm library and Hugging Face Trainer have different variable names (pixel_values vs x))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7c68fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 0.18 | Batch: 20 | Curr Loss: 5.2920\n",
      " >> Epoch: 0.37 | Batch: 40 | Curr Loss: 5.2192\n",
      " >> Epoch: 0.56 | Batch: 60 | Curr Loss: 5.2060\n",
      " >> Epoch: 0.75 | Batch: 80 | Curr Loss: 4.8901\n",
      " >> Epoch: 0.94 | Batch: 100 | Curr Loss: 4.9773\n",
      "{'loss': 5.2121, 'grad_norm': 10.421049118041992, 'learning_rate': 0.0001650793650793651, 'epoch': 1.0}\n",
      "{'eval_loss': 5.13273286819458, 'eval_accuracy': 0.015280135823429542, 'eval_runtime': 35.7113, 'eval_samples_per_second': 16.493, 'eval_steps_per_second': 2.072, 'epoch': 1.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   5.2121 | Training Acc:   2.23%\n",
      " Validation Loss: 5.1327       | Validation Acc: 1.53%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 1.18 | Batch: 20 | Curr Loss: 4.7737\n",
      " >> Epoch: 1.37 | Batch: 40 | Curr Loss: 4.9461\n",
      " >> Epoch: 1.56 | Batch: 60 | Curr Loss: 4.8216\n",
      " >> Epoch: 1.75 | Batch: 80 | Curr Loss: 4.9474\n",
      " >> Epoch: 1.94 | Batch: 100 | Curr Loss: 4.9641\n",
      "{'loss': 4.9344, 'grad_norm': 9.2814302444458, 'learning_rate': 0.00033174603174603175, 'epoch': 2.0}\n",
      "{'eval_loss': 4.870268821716309, 'eval_accuracy': 0.035653650254668934, 'eval_runtime': 34.3857, 'eval_samples_per_second': 17.129, 'eval_steps_per_second': 2.152, 'epoch': 2.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   4.9344 | Training Acc:   2.56%\n",
      " Validation Loss: 4.8703       | Validation Acc: 3.57%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 2.18 | Batch: 20 | Curr Loss: 4.5916\n",
      " >> Epoch: 2.37 | Batch: 40 | Curr Loss: 4.4413\n",
      " >> Epoch: 2.56 | Batch: 60 | Curr Loss: 4.8027\n",
      " >> Epoch: 2.75 | Batch: 80 | Curr Loss: 4.3070\n",
      " >> Epoch: 2.94 | Batch: 100 | Curr Loss: 4.5052\n",
      "{'loss': 4.6218, 'grad_norm': 9.998618125915527, 'learning_rate': 0.0004984126984126984, 'epoch': 3.0}\n",
      "{'eval_loss': 4.662646770477295, 'eval_accuracy': 0.04584040747028863, 'eval_runtime': 34.5556, 'eval_samples_per_second': 17.045, 'eval_steps_per_second': 2.141, 'epoch': 3.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   4.6218 | Training Acc:   5.60%\n",
      " Validation Loss: 4.6626       | Validation Acc: 4.58%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 3.18 | Batch: 20 | Curr Loss: 4.0298\n",
      " >> Epoch: 3.37 | Batch: 40 | Curr Loss: 4.0914\n",
      " >> Epoch: 3.56 | Batch: 60 | Curr Loss: 3.9212\n",
      " >> Epoch: 3.75 | Batch: 80 | Curr Loss: 4.4908\n",
      " >> Epoch: 3.94 | Batch: 100 | Curr Loss: 3.8206\n",
      "{'loss': 4.1612, 'grad_norm': 9.871589660644531, 'learning_rate': 0.000481657848324515, 'epoch': 4.0}\n",
      "{'eval_loss': 4.229859352111816, 'eval_accuracy': 0.08488964346349745, 'eval_runtime': 33.6849, 'eval_samples_per_second': 17.486, 'eval_steps_per_second': 2.197, 'epoch': 4.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   4.1612 | Training Acc:   9.60%\n",
      " Validation Loss: 4.2299       | Validation Acc: 8.49%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 4.18 | Batch: 20 | Curr Loss: 3.6918\n",
      " >> Epoch: 4.37 | Batch: 40 | Curr Loss: 3.4949\n",
      " >> Epoch: 4.56 | Batch: 60 | Curr Loss: 3.7689\n",
      " >> Epoch: 4.75 | Batch: 80 | Curr Loss: 3.7461\n",
      " >> Epoch: 4.94 | Batch: 100 | Curr Loss: 3.6884\n",
      "{'loss': 3.7748, 'grad_norm': 12.703848838806152, 'learning_rate': 0.0004631393298059965, 'epoch': 5.0}\n",
      "{'eval_loss': 4.140162467956543, 'eval_accuracy': 0.09168081494057725, 'eval_runtime': 33.5507, 'eval_samples_per_second': 17.556, 'eval_steps_per_second': 2.206, 'epoch': 5.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   3.7748 | Training Acc:   13.78%\n",
      " Validation Loss: 4.1402       | Validation Acc: 9.17%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 5.18 | Batch: 20 | Curr Loss: 3.3414\n",
      " >> Epoch: 5.37 | Batch: 40 | Curr Loss: 3.5651\n",
      " >> Epoch: 5.56 | Batch: 60 | Curr Loss: 3.6964\n",
      " >> Epoch: 5.75 | Batch: 80 | Curr Loss: 3.9118\n",
      " >> Epoch: 5.94 | Batch: 100 | Curr Loss: 3.2535\n",
      "{'loss': 3.4183, 'grad_norm': 12.894719123840332, 'learning_rate': 0.00044462081128747796, 'epoch': 6.0}\n",
      "{'eval_loss': 3.8540635108947754, 'eval_accuracy': 0.14261460101867574, 'eval_runtime': 33.7321, 'eval_samples_per_second': 17.461, 'eval_steps_per_second': 2.194, 'epoch': 6.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   3.4183 | Training Acc:   19.82%\n",
      " Validation Loss: 3.8541       | Validation Acc: 14.26%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 6.18 | Batch: 20 | Curr Loss: 2.8811\n",
      " >> Epoch: 6.37 | Batch: 40 | Curr Loss: 3.0321\n",
      " >> Epoch: 6.56 | Batch: 60 | Curr Loss: 2.7750\n",
      " >> Epoch: 6.75 | Batch: 80 | Curr Loss: 3.1262\n",
      " >> Epoch: 6.94 | Batch: 100 | Curr Loss: 2.4794\n",
      "{'loss': 3.0809, 'grad_norm': 15.745542526245117, 'learning_rate': 0.00042610229276895945, 'epoch': 7.0}\n",
      "{'eval_loss': 3.767374277114868, 'eval_accuracy': 0.15110356536502548, 'eval_runtime': 33.8883, 'eval_samples_per_second': 17.381, 'eval_steps_per_second': 2.184, 'epoch': 7.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   3.0809 | Training Acc:   24.85%\n",
      " Validation Loss: 3.7674       | Validation Acc: 15.11%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 7.18 | Batch: 20 | Curr Loss: 2.3737\n",
      " >> Epoch: 7.37 | Batch: 40 | Curr Loss: 3.2167\n",
      " >> Epoch: 7.56 | Batch: 60 | Curr Loss: 3.0045\n",
      " >> Epoch: 7.75 | Batch: 80 | Curr Loss: 2.4818\n",
      " >> Epoch: 7.94 | Batch: 100 | Curr Loss: 2.5648\n",
      "{'loss': 2.7353, 'grad_norm': 15.025665283203125, 'learning_rate': 0.00040758377425044093, 'epoch': 8.0}\n",
      "{'eval_loss': 3.752377510070801, 'eval_accuracy': 0.17147707979626486, 'eval_runtime': 34.2292, 'eval_samples_per_second': 17.208, 'eval_steps_per_second': 2.162, 'epoch': 8.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   2.7353 | Training Acc:   30.90%\n",
      " Validation Loss: 3.7524       | Validation Acc: 17.15%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 8.18 | Batch: 20 | Curr Loss: 2.2275\n",
      " >> Epoch: 8.37 | Batch: 40 | Curr Loss: 2.2859\n",
      " >> Epoch: 8.56 | Batch: 60 | Curr Loss: 2.7036\n",
      " >> Epoch: 8.75 | Batch: 80 | Curr Loss: 2.3940\n",
      " >> Epoch: 8.94 | Batch: 100 | Curr Loss: 2.4389\n",
      "{'loss': 2.3561, 'grad_norm': 19.126829147338867, 'learning_rate': 0.0003890652557319224, 'epoch': 9.0}\n",
      "{'eval_loss': 3.7386717796325684, 'eval_accuracy': 0.1833616298811545, 'eval_runtime': 34.0099, 'eval_samples_per_second': 17.318, 'eval_steps_per_second': 2.176, 'epoch': 9.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   2.3561 | Training Acc:   38.10%\n",
      " Validation Loss: 3.7387       | Validation Acc: 18.34%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 9.18 | Batch: 20 | Curr Loss: 2.2218\n",
      " >> Epoch: 9.37 | Batch: 40 | Curr Loss: 1.6501\n",
      " >> Epoch: 9.56 | Batch: 60 | Curr Loss: 2.2966\n",
      " >> Epoch: 9.75 | Batch: 80 | Curr Loss: 2.0740\n",
      " >> Epoch: 9.94 | Batch: 100 | Curr Loss: 1.9161\n",
      "{'loss': 2.0143, 'grad_norm': 21.23949432373047, 'learning_rate': 0.00037054673721340385, 'epoch': 10.0}\n",
      "{'eval_loss': 3.689183235168457, 'eval_accuracy': 0.20203735144312393, 'eval_runtime': 34.2984, 'eval_samples_per_second': 17.173, 'eval_steps_per_second': 2.158, 'epoch': 10.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   2.0143 | Training Acc:   46.40%\n",
      " Validation Loss: 3.6892       | Validation Acc: 20.20%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 10.18 | Batch: 20 | Curr Loss: 1.6331\n",
      " >> Epoch: 10.37 | Batch: 40 | Curr Loss: 1.5368\n",
      " >> Epoch: 10.56 | Batch: 60 | Curr Loss: 1.3764\n",
      " >> Epoch: 10.75 | Batch: 80 | Curr Loss: 1.7003\n",
      " >> Epoch: 10.94 | Batch: 100 | Curr Loss: 1.2809\n",
      "{'loss': 1.6257, 'grad_norm': 14.597826957702637, 'learning_rate': 0.0003520282186948854, 'epoch': 11.0}\n",
      "{'eval_loss': 3.713890790939331, 'eval_accuracy': 0.20882852292020374, 'eval_runtime': 35.9622, 'eval_samples_per_second': 16.378, 'eval_steps_per_second': 2.058, 'epoch': 11.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   1.6257 | Training Acc:   56.59%\n",
      " Validation Loss: 3.7139       | Validation Acc: 20.88%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 11.18 | Batch: 20 | Curr Loss: 0.8422\n",
      " >> Epoch: 11.37 | Batch: 40 | Curr Loss: 1.3648\n",
      " >> Epoch: 11.56 | Batch: 60 | Curr Loss: 1.3099\n",
      " >> Epoch: 11.75 | Batch: 80 | Curr Loss: 1.3702\n",
      " >> Epoch: 11.94 | Batch: 100 | Curr Loss: 1.0156\n",
      "{'loss': 1.2597, 'grad_norm': 13.238887786865234, 'learning_rate': 0.0003335097001763668, 'epoch': 12.0}\n",
      "{'eval_loss': 3.6844232082366943, 'eval_accuracy': 0.23259762308998302, 'eval_runtime': 34.0985, 'eval_samples_per_second': 17.274, 'eval_steps_per_second': 2.17, 'epoch': 12.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   1.2597 | Training Acc:   66.14%\n",
      " Validation Loss: 3.6844       | Validation Acc: 23.26%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 12.18 | Batch: 20 | Curr Loss: 0.7881\n",
      " >> Epoch: 12.37 | Batch: 40 | Curr Loss: 0.7608\n",
      " >> Epoch: 12.56 | Batch: 60 | Curr Loss: 0.8122\n",
      " >> Epoch: 12.75 | Batch: 80 | Curr Loss: 0.8678\n",
      " >> Epoch: 12.94 | Batch: 100 | Curr Loss: 0.8266\n",
      "{'loss': 0.9233, 'grad_norm': 26.633113861083984, 'learning_rate': 0.00031499118165784836, 'epoch': 13.0}\n",
      "{'eval_loss': 3.8944525718688965, 'eval_accuracy': 0.23089983022071306, 'eval_runtime': 33.9419, 'eval_samples_per_second': 17.353, 'eval_steps_per_second': 2.18, 'epoch': 13.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.9233 | Training Acc:   75.72%\n",
      " Validation Loss: 3.8945       | Validation Acc: 23.09%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 13.18 | Batch: 20 | Curr Loss: 0.4332\n",
      " >> Epoch: 13.37 | Batch: 40 | Curr Loss: 0.4664\n",
      " >> Epoch: 13.56 | Batch: 60 | Curr Loss: 0.8525\n",
      " >> Epoch: 13.75 | Batch: 80 | Curr Loss: 0.9066\n",
      " >> Epoch: 13.94 | Batch: 100 | Curr Loss: 0.8918\n",
      "{'loss': 0.6604, 'grad_norm': 19.621997833251953, 'learning_rate': 0.0002964726631393298, 'epoch': 14.0}\n",
      "{'eval_loss': 3.9498450756073, 'eval_accuracy': 0.23769100169779286, 'eval_runtime': 33.9914, 'eval_samples_per_second': 17.328, 'eval_steps_per_second': 2.177, 'epoch': 14.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.6604 | Training Acc:   83.49%\n",
      " Validation Loss: 3.9498       | Validation Acc: 23.77%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 14.18 | Batch: 20 | Curr Loss: 0.4451\n",
      " >> Epoch: 14.37 | Batch: 40 | Curr Loss: 0.4983\n",
      " >> Epoch: 14.56 | Batch: 60 | Curr Loss: 0.4781\n",
      " >> Epoch: 14.75 | Batch: 80 | Curr Loss: 0.5167\n",
      " >> Epoch: 14.94 | Batch: 100 | Curr Loss: 0.4029\n",
      "{'loss': 0.4541, 'grad_norm': 22.221426010131836, 'learning_rate': 0.00027795414462081133, 'epoch': 15.0}\n",
      "{'eval_loss': 4.094743728637695, 'eval_accuracy': 0.22241086587436332, 'eval_runtime': 34.1712, 'eval_samples_per_second': 17.237, 'eval_steps_per_second': 2.166, 'epoch': 15.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.4541 | Training Acc:   89.97%\n",
      " Validation Loss: 4.0947       | Validation Acc: 22.24%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 15.18 | Batch: 20 | Curr Loss: 0.2231\n",
      " >> Epoch: 15.37 | Batch: 40 | Curr Loss: 0.2235\n",
      " >> Epoch: 15.56 | Batch: 60 | Curr Loss: 0.3530\n",
      " >> Epoch: 15.75 | Batch: 80 | Curr Loss: 0.4397\n",
      " >> Epoch: 15.94 | Batch: 100 | Curr Loss: 0.2933\n",
      "{'loss': 0.3313, 'grad_norm': 38.03312301635742, 'learning_rate': 0.00025943562610229276, 'epoch': 16.0}\n",
      "{'eval_loss': 4.138522624969482, 'eval_accuracy': 0.22580645161290322, 'eval_runtime': 34.2763, 'eval_samples_per_second': 17.184, 'eval_steps_per_second': 2.159, 'epoch': 16.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.3313 | Training Acc:   92.71%\n",
      " Validation Loss: 4.1385       | Validation Acc: 22.58%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 16.18 | Batch: 20 | Curr Loss: 0.2428\n",
      " >> Epoch: 16.37 | Batch: 40 | Curr Loss: 0.1354\n",
      " >> Epoch: 16.56 | Batch: 60 | Curr Loss: 0.3285\n",
      " >> Epoch: 16.75 | Batch: 80 | Curr Loss: 0.3511\n",
      " >> Epoch: 16.94 | Batch: 100 | Curr Loss: 0.4046\n",
      "{'loss': 0.2256, 'grad_norm': 11.726457595825195, 'learning_rate': 0.00024091710758377424, 'epoch': 17.0}\n",
      "{'eval_loss': 4.2865800857543945, 'eval_accuracy': 0.21731748726655348, 'eval_runtime': 34.649, 'eval_samples_per_second': 16.999, 'eval_steps_per_second': 2.136, 'epoch': 17.0}\n",
      "\n",
      "================================================================================\n",
      " Training Loss:   0.2256 | Training Acc:   95.70%\n",
      " Validation Loss: 4.2866       | Validation Acc: 21.73%\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Epoch: 17.18 | Batch: 20 | Curr Loss: 0.2826\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 115\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# the actual training\u001b[39;00m\n\u001b[1;32m    107\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TimmTrainer(\n\u001b[1;32m    108\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    109\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m    113\u001b[0m )\n\u001b[0;32m--> 115\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    117\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_new_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model saved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2326\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2327\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2328\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   2329\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2330\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/trainer.py:2618\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2616\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2617\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2618\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_batch_samples(epoch_iterator, num_batches, args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2619\u001b[0m \u001b[38;5;66;03m# Store the number of batches for current gradient accumulation\u001b[39;00m\n\u001b[1;32m   2620\u001b[0m \u001b[38;5;66;03m# This is used to correctly scale the loss when the last accumulation step has fewer batches\u001b[39;00m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_gradient_accumulation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/trainer.py:5654\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5652\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5653\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5654\u001b[0m         batch_samples\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mnext\u001b[39m(epoch_iterator))\n\u001b[1;32m   5655\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5656\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/accelerate/data_loader.py:579\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_blocking)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state_dict()\n\u001b[0;32m--> 579\u001b[0m next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    738\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:788\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    787\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 788\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    790\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/datasets/arrow_dataset.py:2880\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2878\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m   2879\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2880\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(keys)\n\u001b[1;32m   2881\u001b[0m     n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[1;32m   2882\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/datasets/arrow_dataset.py:2876\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolars\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2875\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Column(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[0;32m-> 2876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(key)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/datasets/arrow_dataset.py:2858\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2856\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2857\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2858\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[1;32m   2859\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[1;32m   2860\u001b[0m )\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/datasets/formatting/formatting.py:658\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    656\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m formatter(pa_table, query_type\u001b[38;5;241m=\u001b[39mquery_type)\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/datasets/formatting/formatting.py:415\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_batch(pa_table)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/datasets/formatting/formatting.py:471\u001b[0m, in \u001b[0;36mPythonFormatter.format_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyBatch(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 471\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_batch(pa_table)\n\u001b[1;32m    472\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_batch(batch)\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/datasets/formatting/formatting.py:150\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pa_table\u001b[38;5;241m.\u001b[39mto_pydict()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# using the 'timm' library for CoAtNet: update: maybe not\n",
    "model = timm.create_model(\n",
    "    MODEL_NAME, \n",
    "    pretrained=False, \n",
    "    num_classes=200 \n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "class TimmTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.epoch_train_loss = 0.0\n",
    "        self.epoch_train_acc = 0.0\n",
    "        self.epoch_steps = 0\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        pixel_values = inputs.get(\"pixel_values\")\n",
    "        labels = inputs.get(\"labels\")\n",
    "        \n",
    "        logits = model(pixel_values)\n",
    "        loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits, labels)\n",
    "        \n",
    "        if model.training:\n",
    "            with torch.no_grad():\n",
    "                preds = torch.argmax(logits, dim=-1)\n",
    "                acc = (preds == labels).float().mean().item()\n",
    "                \n",
    "                self.epoch_train_loss += loss.item()\n",
    "                self.epoch_train_acc += acc\n",
    "                self.epoch_steps += 1\n",
    "                \n",
    "                if self.epoch_steps % 20 == 0:\n",
    "                    current_epoch_float = self.state.epoch if self.state.epoch is not None else 0\n",
    "                    print(f\" >> Epoch: {current_epoch_float:.2f} | Batch: {self.epoch_steps} | Curr Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        return (loss, logits) if return_outputs else loss\n",
    "    \n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        pixel_values = inputs.get(\"pixel_values\")\n",
    "        labels = inputs.get(\"labels\")\n",
    "        with torch.no_grad():\n",
    "            logits = model(pixel_values)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "        if prediction_loss_only:\n",
    "            return (loss, None, None)\n",
    "        return (loss, logits, labels)\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "        metrics = super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
    "        \n",
    "        avg_train_loss = self.epoch_train_loss / self.epoch_steps if self.epoch_steps > 0 else 0\n",
    "        avg_train_acc = self.epoch_train_acc / self.epoch_steps if self.epoch_steps > 0 else 0\n",
    "        \n",
    "        val_loss = metrics.get(f\"{metric_key_prefix}_loss\", 0.0)\n",
    "        val_acc = metrics.get(f\"{metric_key_prefix}_accuracy\", 0.0)\n",
    "        \n",
    "        epoch_num = int(self.state.epoch) if self.state.epoch else 0\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\" Training Loss:   {avg_train_loss:.4f} | Training Acc:   {avg_train_acc*100:.2f}%\")\n",
    "        print(f\" Validation Loss: {val_loss:.4f}       | Validation Acc: {val_acc*100:.2f}%\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        # resetting counters\n",
    "        self.epoch_train_loss = 0.0\n",
    "        self.epoch_train_acc = 0.0\n",
    "        self.epoch_steps = 0\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "# accuracy metrics:\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return accuracy.compute(predictions=preds, references=p.label_ids)\n",
    "\n",
    "# training \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=32, \n",
    "    num_train_epochs=30,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0.05,\n",
    "    warmup_ratio=0.1,\n",
    "    \n",
    "    disable_tqdm=True, # for now bc i dont like it - Julia\n",
    "    \n",
    "    logging_strategy=\"epoch\", \n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    \n",
    "    dataloader_num_workers=0,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# the actual training\n",
    "trainer = TimmTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"final_new_model\")\n",
    "print(\"Best model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a80576-44a1-4953-a5f1-d1503c9413ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7922e-be11-49ba-81a9-1732dd733f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
