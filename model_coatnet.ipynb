{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e521e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (1.0.22)\n",
      "Requirement already satisfied: torch in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from timm) (2.9.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from timm) (0.24.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from timm) (0.34.4)\n",
      "Requirement already satisfied: safetensors in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from timm) (0.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (24.2)\n",
      "Requirement already satisfied: requests in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from huggingface_hub->timm) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from requests->huggingface_hub->timm) (2025.8.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from torch->timm) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from torch->timm) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from torchvision->timm) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from torchvision->timm) (11.1.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from ipywidgets) (8.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.12 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: executing in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\jkowa\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c506a5cf",
   "metadata": {},
   "source": [
    "# new model - coatnet\n",
    "hybrid architecture - Convolution + Attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e284eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_from_disk\n",
    "import timm\n",
    "from transformers import (\n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "from torchvision.transforms import (\n",
    "    Compose, Resize, CenterCrop, ToTensor, Normalize, \n",
    "    RandomHorizontalFlip, RandomResizedCrop\n",
    ")\n",
    "\n",
    "DATA_PATH = \"processed_bird_data\"\n",
    "OUTPUT_DIR = \"new_model_checkpoints\"\n",
    "\n",
    "# Using 'coatnet_0_rw_224' model, with '0' to use the smallest version to avoid overfitting:\n",
    "MODEL_NAME = \"coatnet_0_rw_224\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4adfe7b",
   "metadata": {},
   "source": [
    "Applying Aggressive Data Augmentation to prevent overfitting:\n",
    "\n",
    "1. Does random resize/zoom (scale 0.8â€“1.0). Forces the model to recognize a bird by looking at its specific feature (e.g. the head, wing, etc.) instead of the background (e.g. tress).\n",
    "2. Incorporates horizontal flipping to double the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07295e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset.\n",
      "Applying transforms and removing raw images...\n",
      "Data ready.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset.\")\n",
    "dataset = load_from_disk(DATA_PATH)\n",
    "\n",
    "# transformations:\n",
    "# normalization of values for ImageNet:\n",
    "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# training: random crops + flips (noise helps it learn):\n",
    "_train_transforms = Compose([\n",
    "    RandomResizedCrop(224, scale=(0.8, 1.0)), \n",
    "    RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# validation - deterministic center crop\n",
    "_val_transforms = Compose([\n",
    "    Resize(256),\n",
    "    CenterCrop(224),\n",
    "    ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "def train_transforms(batch):\n",
    "    batch[\"pixel_values\"] = [_train_transforms(image.convert(\"RGB\")) for image in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "def val_transforms(batch):\n",
    "    batch[\"pixel_values\"] = [_val_transforms(image.convert(\"RGB\")) for image in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "# using .map() instead of .set_transform() because set_transform keeps the original columns accessible, and we want to delete those raw pngs to avoid program crashing.\n",
    "print(\"Applying transforms and removing raw images...\")\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].map(\n",
    "    train_transforms, \n",
    "    batched=True, \n",
    "    remove_columns=[\"image\"]\n",
    ")\n",
    "\n",
    "dataset[\"validation\"] = dataset[\"validation\"].map(\n",
    "    val_transforms, \n",
    "    batched=True, \n",
    "    remove_columns=[\"image\"]\n",
    ")\n",
    "\n",
    "print(\"Data ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66360a0",
   "metadata": {},
   "source": [
    "# Training\n",
    "Initializing CoAtNet model with random weights, no pretraining. \n",
    "\n",
    "It uses standard Convolutional layers in the early stages to extract low-level features (edges, textures), and then uses Transformer layers in the final stages to understand the global shape of the bird. Also:\n",
    "\n",
    "1. High learning rate;\n",
    "2. 15 epochs;\n",
    "3. Uses regularization to prevent the model from memorizing the training images.\n",
    "\n",
    "(using TimmTrainer class as the timm library and Hugging Face Trainer have different variable names (pixel_values vs x))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c68fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jkowa\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# using the 'timm' library for CoAtNet: update: maybe not\n",
    "model = timm.create_model(\n",
    "    MODEL_NAME, \n",
    "    pretrained=False, \n",
    "    num_classes=200 \n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "class TimmTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.epoch_train_loss = 0.0\n",
    "        self.epoch_train_acc = 0.0\n",
    "        self.epoch_steps = 0\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        pixel_values = inputs.get(\"pixel_values\")\n",
    "        labels = inputs.get(\"labels\")\n",
    "        \n",
    "        logits = model(pixel_values)\n",
    "        loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits, labels)\n",
    "        \n",
    "        if model.training:\n",
    "            with torch.no_grad():\n",
    "                preds = torch.argmax(logits, dim=-1)\n",
    "                acc = (preds == labels).float().mean().item()\n",
    "                \n",
    "                self.epoch_train_loss += loss.item()\n",
    "                self.epoch_train_acc += acc\n",
    "                self.epoch_steps += 1\n",
    "                \n",
    "                if self.epoch_steps % 20 == 0:\n",
    "                    current_epoch_float = self.state.epoch if self.state.epoch is not None else 0\n",
    "                    print(f\" >> Epoch: {current_epoch_float:.2f} | Batch: {self.epoch_steps} | Curr Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        return (loss, logits) if return_outputs else loss\n",
    "    \n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        pixel_values = inputs.get(\"pixel_values\")\n",
    "        labels = inputs.get(\"labels\")\n",
    "        with torch.no_grad():\n",
    "            logits = model(pixel_values)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "        if prediction_loss_only:\n",
    "            return (loss, None, None)\n",
    "        return (loss, logits, labels)\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "        metrics = super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
    "        \n",
    "        avg_train_loss = self.epoch_train_loss / self.epoch_steps if self.epoch_steps > 0 else 0\n",
    "        avg_train_acc = self.epoch_train_acc / self.epoch_steps if self.epoch_steps > 0 else 0\n",
    "        \n",
    "        val_loss = metrics.get(f\"{metric_key_prefix}_loss\", 0.0)\n",
    "        val_acc = metrics.get(f\"{metric_key_prefix}_accuracy\", 0.0)\n",
    "        \n",
    "        epoch_num = int(self.state.epoch) if self.state.epoch else 0\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\" Training Loss:   {avg_train_loss:.4f} | Training Acc:   {avg_train_acc*100:.2f}%\")\n",
    "        print(f\" Validation Loss: {val_loss:.4f}       | Validation Acc: {val_acc*100:.2f}%\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        # resetting counters\n",
    "        self.epoch_train_loss = 0.0\n",
    "        self.epoch_train_acc = 0.0\n",
    "        self.epoch_steps = 0\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "# accuracy metrics:\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return accuracy.compute(predictions=preds, references=p.label_ids)\n",
    "\n",
    "# training \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=32, \n",
    "    num_train_epochs=15,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0.05,\n",
    "    warmup_ratio=0.1,\n",
    "    \n",
    "    disable_tqdm=True, # for now bc i dont like it - Julia\n",
    "    \n",
    "    logging_strategy=\"epoch\", \n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    \n",
    "    dataloader_num_workers=0,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# the actual training\n",
    "trainer = TimmTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"final_new_model\")\n",
    "print(\"Best model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a80576-44a1-4953-a5f1-d1503c9413ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7922e-be11-49ba-81a9-1732dd733f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
